[{"authors":["admin"],"categories":null,"content":"何志坚，男，1987年12月生，广东湛江人，华南理工大学数学学院副教授、硕士生导师。清华大学统计学博士，华南理工大学数学与应用数学本科。研究兴趣为统计计算与建模、随机模拟方法及其应用、金融工程。相关研究发表在统计学和计算科学领域顶级期刊，如统计学四大期刊Journal of the Royal Statistical Society: Series B，计算科学顶级期刊SIAM Journal on Numerical Analysis，SIAM Journal on Scientific Computing和Mathematics of Computation，运筹管理权威期刊European Journal of Operational Research等。博士论文获得新世界数学奖银奖。曾获第十四届金融系统工程与工程管理国际年会(FSERM2016)优秀论文奖。国家自然科学基金、广东省自然科学基金通讯评审专家。\n","date":1595203200,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1595203200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/zh/author/%E4%BD%95%E5%BF%97%E5%9D%9A/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/author/%E4%BD%95%E5%BF%97%E5%9D%9A/","section":"authors","summary":"何志坚，男，1987年12月生，广东湛江人，华南理工大学数学学院副教授、硕士生导师。清华大学统计学博士，华南理工大学数学与应用数学本科。研究兴趣为统计计算与建模、随机模拟方法及其应用、金融工程。相关研究发表在统计学和计算科学领域顶级期刊，如统计学四大期刊Journal of the Royal Statistical Society: Series B，计算科学顶级期刊SIAM Journal on Numerical Analysis，SIAM Journal on Scientific Computing和Mathematics of Computation，运筹管理权威期刊European Journal of Operational Research等。博士论文获得新世界数学奖银奖。曾获第十四届金融系统工程与工程管理国际年会(FSERM2016)优秀论文奖。国家自然科学基金、广东省自然科学基金通讯评审专家。","tags":null,"title":"何志坚","type":"authors"},{"authors":null,"categories":null,"content":"教材   中文教材\n  英文教材\n  课程资源    我之前写的讲义\n   斯坦福大学Art Owen教授的讲义\n  ","date":1596931200,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1596931200,"objectID":"899b6a6afa5d68e0a5e2b31b85e37795","permalink":"/zh/courses/stat/","publishdate":"2020-08-09T00:00:00Z","relpermalink":"/zh/courses/stat/","section":"courses","summary":"这是数理统计课程","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"教材   中文教材\n  英文教材\n  课程资源 ","date":1596931200,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1596931200,"objectID":"38d94ee05c8252999a5107be669c3de6","permalink":"/zh/courses/bayes/","publishdate":"2020-08-09T00:00:00Z","relpermalink":"/zh/courses/bayes/","section":"courses","summary":"这是贝叶斯统计课程","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":"频率学派与贝叶斯学派 频率学派（传统学派）   频率学派认为样本信息来自总体，仅通过研究样本信息可以对总体信息做出合理的推断和估计，并且样本越多，就越准确。\n  代表性人物：费希尔 (R. A. Fisher, 1890-1962)\n  贝叶斯学派  起源于英国学者贝叶斯(T. Bayes, 1702-1761)在1763年发表的著名论文《论有关机遇问题的求解》 最基本观点：任何一个未知量都可以看作是随机的，应该用一个概率分布去描述未知参数，而不是频率派认为的固定值。这种信息称为先验信息，是主观信息。  贝叶斯公式 案例一：天蝎号核潜艇搜救 1968年5月，美国海军的天蝎号核潜艇在大西洋亚速海海域突然失踪，潜艇和艇上的99名海军官兵全部杳无音信。按照事后调查报告的说法，罪魁祸首是这艘潜艇上的一枚奇怪的鱼雷，发射出去后竟然敌我不分，扭头射向自己，让潜艇中弹爆炸。\n为了寻找天蝎号的位置，美国政府从国内调集了包括多位专家的搜索部队前往现场，其中包括一位名叫John Craven的数学家，他的头衔是“美国海军特别计划部首席科学家”。在搜寻潜艇的问题上，Craven提出的方案使用了贝叶斯公式。\n这种方法已经用于2009年法航447和2014年马航370的搜救。 具体原理参考： Bayesian search theory\n20英里海域的概率图 案例二：联邦党人文集作者公案  1787年5月，美国各州的代表在费城召开制宪会议。 1787年9月，美国的宪法草案被分发到各州进行讨论。一批反对派以“反联邦主义者”为笔名，发表了大量文章对该草案提出批评。宪法起草人之一亚历山大·汉密尔顿着急了，他找到曾任外交国务秘书（即后来的国务卿）的约翰·杰伊，以及纽约市国会议员麦迪逊，一同以Publius的笔名发表文章，向公众解释为什么美国需要一部宪法。他们走笔如飞，通常在一周之内就会发表3-4篇新的评论。 1788年，他们所写的85篇文章结集出版，这就是美国历史上著名的《联邦党人文集》。  案例二：联邦党人文集作者公案   1810年，汉密尔顿接受了一个政敌的决斗挑战。在决斗之前数日，汉密尔顿自知时日不多，他列出了一份《联邦党人文集》的作者名单。\n  1818年，麦迪逊又提出了另一份作者名单。这两份名单并不一致。在85篇文章中，有73篇文章的作者身份较为明确，其余12篇存在争议。\n  1955年，哈佛大学统计学教授Fredrick Mosteller找到芝加哥大学的年轻统计学家David Wallance，建议他跟自己一起做一个小课题，他想用统计学的方法，鉴定出《联邦党人文集》的作者身份。\n  采用的方法是以贝叶斯公式为核心的分类算法。先挑选一些能够反映作者写作风格的词汇，在已经确定了作者的文本中，对这些特征词汇的出现频率进行统计，然后再统计这些词汇在那些不确定作者的文本中的出现频率，从而根据词频的差别推断作者归属。\n  贝叶斯的发展 经典统计学的困难  经典统计学比较适合于解决小型的问题，同时需要足够多的样本数据 都大数据时代了，还存在数据稀疏性问题吗？致病基因  贝叶斯网络带来工具革命  龙卷风的形成、星系的起源、致病基因、大脑的运作机制等，要揭示隐藏在这些问题背后的规律，就必须理解它们的成因网络 贝叶斯公式+图论  贝叶斯统计的发展 应用领域  自然语言处理：计算机翻译语言、识别语音、认识文字和海量文献的检索   南京市长江大桥欢迎您!\n  人工智能、无人驾驶 垃圾短信、垃圾邮件识别  贝叶斯决策  如何在一个陌生的地方找餐馆吃饭？  一些评价 **Berger (1985)**说：\n “防止误用的最好方法是给人们在先验信息方面以适当的教育，另外在贝叶斯分析的最后报告中，应将先验分开来写，以便使其他人对主观输入的合理性做出评价。”\n **Good (1973)**更是直截了当的说：\n “主观主义者直抒他们的判断，而客观主义者以假设来掩盖其判断，并以此享受科学客观性的荣耀。”\n ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"5618aff72171059f504dafc78155192d","permalink":"/zh/courses/bayes/chap1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/chap1/","section":"courses","summary":"频率学派与贝叶斯学派 频率学派（传统学派）   频率学派认为样本信息来自总体，仅通过研究样本信息可以对总体信息做出合理的推断和估计，并且样本越多，就越准确。\n  代表性人物：费希尔 (R. A. Fisher, 1890-1962)\n  贝叶斯学派  起源于英国学者贝叶斯(T. Bayes, 1702-1761)在1763年发表的著名论文《论有关机遇问题的求解》 最基本观点：任何一个未知量都可以看作是随机的，应该用一个概率分布去描述未知参数，而不是频率派认为的固定值。这种信息称为先验信息，是主观信息。  贝叶斯公式 案例一：天蝎号核潜艇搜救 1968年5月，美国海军的天蝎号核潜艇在大西洋亚速海海域突然失踪，潜艇和艇上的99名海军官兵全部杳无音信。按照事后调查报告的说法，罪魁祸首是这艘潜艇上的一枚奇怪的鱼雷，发射出去后竟然敌我不分，扭头射向自己，让潜艇中弹爆炸。\n为了寻找天蝎号的位置，美国政府从国内调集了包括多位专家的搜索部队前往现场，其中包括一位名叫John Craven的数学家，他的头衔是“美国海军特别计划部首席科学家”。在搜寻潜艇的问题上，Craven提出的方案使用了贝叶斯公式。\n这种方法已经用于2009年法航447和2014年马航370的搜救。 具体原理参考： Bayesian search theory","tags":null,"title":"第1章","type":"docs"},{"authors":null,"categories":null,"content":"","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"a20063cd0bbfd27711e6434acc4f62fb","permalink":"/zh/courses/stat/chap1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/stat/chap1/","section":"courses","summary":"","tags":null,"title":"第一章","type":"docs"},{"authors":null,"categories":null,"content":"\rThis note is adapted to the paper entitled “Variation Inference: A Review for Statisticans” by Blei et al. (2017).\nBasic ideas of VI\rLet \\(z=z_{1:m}\\) be the latent variables that govern the distribution of the data (observations) \\(x=x_{1:n}\\).\rThe prior is denoted by \\(p(z)\\). The likelihood is \\(p(x|z)\\). The posterior thus is given by\r\\[p(z|x)=\\frac{p(z)p(x|z)}{p(x)}\\propto p(z)p(x|z).\\]\rThe denominator \\(p(x)\\) contains the marginal density of the obsevations, also called the evidence.\n\rABC algorithms provide a kind of approximations of the posterior in the context of simulation.\n\rVI provides another kind of approximations of the posterior by minizing the Kullback-Leibler (KL) divergence to the exact posterior over a family of approximate densities \\(\\mathcal Q\\). That is\r\\[q^*(z) = \\arg \\min_{q(z)\\in\\mathcal Q} KL (q(z)||p(z|x)).\\]\rThe KL divergence (also called relative entropy) is a measure of how one probability distribution is different from a second, reference probability distribution. The formal definition of KL divergence is \\[KL(p_1||p_2)=E_{p_1}[\\log (p_1(x)/p_2(x))]=E_{p_1}[\\log p_1(x)]-E_{p_1}[\\log p_2(x)].\\]\n\r\\(KL(p_1||p_2)\\ge 0\\), where the equality holds iff \\(p_1(z)=p_2(z)\\) w.p.1. This can be proved via Jensen inequality. Noting that\r\\[KL(p_1||p_2)=-E_{p_1}[\\log (p_2(x)/p_1(x))]\\ge -\\log E_{p_1}[p_2(x)/p_1(x)]=-\\log \\int \\frac{p_2(x)}{p_1(x)} p_1(x) dx =0.\\]\rThe equality holds iff \\(p_2(x)/p_1(x)\\) is constant w.p.1.\n\rIt is a distribution-wise asymmetric measure and thus does not qualify as a statistical metric of spread, i.e, \\(KL(p_1||p_2)\\neq KL(p_2||p_1)\\).\n\rIt also does not satisfy the triangle inequality \\(KL(p_1||p_2)+KL(p_2||p_3)\\ge KL(p_1||p_3)\\).\n\r\rNote that the objective is not computable because it requires computing \\(\\log p(x)\\), which is typically infeasible. To see why,\r\\[KL (q(z)||p(z|x))=E_{q}[\\log q(z)]-E_{q}[\\log p(z|x)]=E_{q}[\\log q(z)]-E_{q}[\\log p(z)]-E_{q}[\\log p(x|z)]+\\log p(x).\\]\rAs a result, we optimize an alternative objective that is equivalent to the KL up to an added constant,\r\\[\\begin{equation}\rELBO(q)=E_{q}[\\log(p(x,z)/q(z))]=E_{q}[\\log p(z)]+E_{q}[\\log p(x|z)]-E_{q}[\\log q(z)].\\label{eq:elbo}\r\\end{equation}\\]\rThis function is called the evidence lower bound (ELBO). It is easy to see that\r\\[ELBO(q)=-KL (q(z)||p(z))+\\log p(x).\\]\rSince the log-evidence is constant,\r\\[\\begin{equation}\rq^*(z) = \\arg \\min_{q(z)\\in\\mathcal Q} KL (q(z)||p(z|x))=\\arg\\max_{q(z)\\in\\mathcal Q} ELBO(q).\r\\label{eq:elboopt}\r\\end{equation}\\]\n\rIt follows from \\(KL(p_1||p_2)\\ge 0\\) that \\(ELBO(q)\\le \\log p(x)\\) for any \\(q\\). This means the ELBO is a lower-bound of the log-evidence, explaining its name.\n\rFrom the second equality in , maximazing the ELBO mirrors the usual balance between likelihood and prior.\n\r\r\rThe Mean-Field Variational Family\rThe complexity of the family determines the complexity of the optimization; it is more difficulty to optimize over a complex family than a simple family. We next focus on the mean-field variational family,\r\\[\\begin{equation}\rq(z) = \\prod_{j=1}^m q_j(z_j).\\label{eq:mfvf}\r\\end{equation}\\]\rEach latent variable \\(z_j\\) is governed by its own variational factor, the density \\(q_j\\). That is \\(z_j\\stackrel{ind}\\sim q_j\\).\nOne may specify the parametric form of the individual variational factors. In principle, each can take on any parametric form appropriate to the corresponding random variable.\n\rA continous variable might have a Gaussian factor.\n\rA categorical variable will typically have a categorical factor.\n\r\r\rCoordinate Ascent Mean-Field VI\rThis section describe one of the most commonly used algorithms for solving the optimizatin problem subject to the mean-field variational family . The coordinate ascent VI (CAVI) iteratively optimizes each factor of the mean-field variation density, while holding the others fixed. It climbs the ELBO to a local optimum.\nLet \\(z_{-j}\\) be the vector of \\(z\\) by removing the \\(j\\)th component \\(z_j\\), and let \\(p(z_j|z_{-j},x)\\) be the complete conditional of \\(z_j\\) given all of the other latent variables in the model and the observations.\rFixing the other variational factors, \\(q_\\ell(z_\\ell)\\), \\(\\ell\\neq j\\), the optimal \\(q_j(z_j)\\) is then propotional to the exponentiated expected log of the complete conditional,\r\\[\\begin{equation}\rq_j^*(z_j) \\propto \\exp\\{E_{-j}[\\log p(z_j|z_{-j},x)]\\}\\propto \\exp\\{E_{-j}[\\log p(x,z)]\\},\\label{eq:cavi}\r\\end{equation}\\]\rwhere the expectation is with respective to the currently fixed variational density over \\(z_{-j}\\), i.e, \\(\\prod_{\\ell\\neq j} q_\\ell (z_\\ell)\\). To see why, when fixing the other variational factors, \\(q_\\ell(z_\\ell)\\), \\(\\ell\\neq j\\), it follows from that\r\\[\\begin{align*}\rELBO(q) \u0026amp;= ELBO(q_j) = E_{q}[\\log(p(x,z)/q(z))] \\\\\u0026amp;= E_{q}[\\log(p(z_{j}|z_{-j},x)p(z_{-j},x)/q_{j}(z_j)/q_{-j}(z_{-j}))]\\\\\r\u0026amp; = E_{q}[\\log(p(z_{j}|z_{-j},x)/q_j(z_j)] + \\text{const}\\\\\r\u0026amp;=E_{q_j}[E_{-j}[\\log(p(z_{j}|z_{-j},x)]-\\log q_j(z_j)] + \\text{const}\\\\\r\u0026amp;=E_{q_j}[\\log (\\exp\\{E_{-j}[\\log p(z_j|z_{-j},x)]\\}/q_j(z_j))]+ \\text{const}\\\\\r\u0026amp;= - KL(q_j(z_j)||c\\exp\\{E_{-j}[\\log p(z_j|z_{-j},x)]\\})+ \\text{const},\r\\end{align*}\\]\rwhere \\(c\\) is a normalized constant such that \\(c\\exp\\{E_{-j}[\\log p(z_j|z_{-j},x)]\\) is a PDF.\rSince \\(KL\\ge 0\\), the maximization of ELBO attains at \\(q_j(z_j)=c\\exp\\{E_{-j}[\\log p(z_j|z_{-j},x)]\\}\\) w.p.1. Therefore, the optimal \\(q_j(z_j)\\) is propotional to \\(\\exp\\{E_{-j}[\\log p(z_j|z_{-j},x)]\\}\\).\nCAVI goes as follows: Initizlize the variational factors \\(q_j(z_j)\\); Update each factor of the mean-field variation density by , while holding the others fixed, until the ELBO converges. To check the convergence, we may compute the ELBO after a (few) loop of all the factors.\nThe ELBO is (generally) a nonconvex objective function. CAVI only guarantees to a local optimum, which can be sensitive to iniitialization. Also, the updated variational factor should have a closed form.\n\rApplication I: Bayesian mixture of Gaussians\rAs a concrete example, we consider a Bayesian mixture of unit-variance univariate Gaussians. There are \\(K\\) mixture components, corresponding to \\(K\\) Gaussian distributions with means \\(\\mu=(\\mu_1,\\dots,\\mu_K)\\). Given the means, the data is generated via\r\\[x_i|\\mu,\\alpha\\stackrel{iid}{\\sim} \\sum_{k=1}^K \\alpha_{k} N(\\mu_k,1),\\]\rwhere \\(\\alpha_{k}\u0026gt;0\\) is the probablity drawn from the \\(k\\)th Guassian with \\(\\sum_{k=1}^K \\alpha_{k} =1\\).\nWe now add some latent variables to reformulate the model. This is actually a technique of data augment. Let the latent variable \\(c_i\\) be an indicator \\(K\\)-vector, all zeros expect for a one in the position corresponding to \\(x_i\\)’s cluster. There are \\(K\\) possible values for \\(c_i\\). As a result, \\(x_i|\\mu,c_i\\sim N(c_i^\\top \\mu,1)\\), \\(c_i\\sim \\text{categorical}(\\alpha)=:CG(\\alpha)\\), where \\(\\alpha=(\\alpha_{1},\\dots,\\alpha_{K})\\). Assume that the mean parameters are drawn independently from a common prior \\(p(\\mu_k)\\sim N(0,\\sigma^2)\\); the prior variance \\(\\sigma^2\\) ia a hyperparameter; and the prior for the latent indicators is \\(c_i\\sim CG(1/K,1/K,\\dots,1/K)\\).\nThe full hierarchical model is\r\\[\\begin{align}\r\\mu_k\u0026amp;\\stackrel{iid}{\\sim} N(0,\\sigma^2), \u0026amp; k=1,\\dots,K,\\\\\rc_i\u0026amp;\\stackrel{iid}{\\sim} \\text{categorical}(1/K,1/K,\\dots,1/K), \u0026amp; i=1,\\dots, n,\\\\\rx_i|\\mu,c_i\u0026amp;\\stackrel{ind}{\\sim} N(c_i^\\top \\mu,1), \u0026amp;i=1,\\dots, n.\r\\end{align}\\]\rThe latent variables are \\(z=(\\mu, c)\\). The joint density of latent and observed variables is\r\\[p(\\mu,c,x) = p(\\mu) \\prod_{i=1}^n p(c_i)p(x_i|c_i,\\mu).\\]\rThe evidence is\r\\[\\begin{align}\rp(x)= \\int p(\\mu) \\prod_{i=1}^n \\sum_{c_i} p(c_i)p(x_i|c_i,\\mu) d\\mu=\\sum_{c_1,\\dots,c_n}\\prod_{i=1}^n p(c_i) \\int p(\\mu) \\prod_{i=1}^n p(x_i|c_i,\\mu) d\\mu.\\label{eq:gmmevi}\r\\end{align}\\]\rThanks to conjugacy between the Gaussian prior on the components and the Gaussian likelihood, each individual integral \\(I(c_1,\\dots,c_n):=\\int p(\\mu) \\prod_{i=1}^n p(x_i|c_i,\\mu) d\\mu\\) is computable. However, the total cases of the configuration \\((c_1,\\dots,c_n)\\) is \\(K^n\\). As a result, the complexity of computing is \\(O(K^n)\\), which is infeasible for moderate sample size \\(n\\) and \\(K\\). For example, when \\(K=3\\) and \\(n=100\\), \\(K^n = 3^{100}\\approx 5.2\\times 10^{47}\\). In this sense, we can say that the evidence is intractable.\nIn VI, we choose the mean-field variational family as the form\r\\[q(\\mu,c) = \\prod_{k=1}^K q(\\mu_k;m_k,s_k^2)\\prod_{i=1}^nq(c_i;\\psi_i),\\]\rwhere the variational factor \\(q(\\mu_k;m_k,s_k^2)\\) for the mean \\(\\mu_i\\) is a Guassian \\(N(m_k,s_k^2)\\), and the variational factor \\(q(c_i;\\psi_i)\\) for the indicator is \\(CG(\\psi_i)\\).\rBy , we have\r\\[\\begin{align}\rELBO(m,s^2,\\psi)\u0026amp;=E_{q}[\\log p(z)]+E_{q}[\\log p(x|z)]-E_{q}[\\log q(z)]\\notag\\\\\r\u0026amp;=\\sum_{k=1}^K E_{\\mu_k\\sim N(m_k,s_k^2)}[\\log p(\\mu_k)]\\notag\\\\\r\u0026amp;\\quad+\\sum_{i=1}^n (E_{c_i\\sim CG(\\psi_i)}[\\log p(c_i)]+E_{c_i\\sim CG(\\psi_i),\\mu\\sim N(m,\\text{diag}(s^2))}[\\log p(x_i|c_i,\\mu)])\\notag\\\\\r\u0026amp;\\quad-\\sum_{i=1}^n E_{c_i\\sim CG(\\psi_i)}[\\log q(c_i;\\psi_i)]-\\sum_{k=1}^K E_{\\mu_k\\sim N(m_k,s_k^2)}[\\log q(\\mu_k;m_k,s_k^2)]\\notag\\\\\r\u0026amp;=\\frac K 2-K\\log\\sigma-n\\log K-\\frac 12 n\\log(2\\pi)+\\frac 1 2\\sum_{i=1}^n x_i^2+\\sum_{k=1}^K\\left[\\log(s_k)-\\frac{m_k^2+s_k^2}{2\\sigma^2}\\right] \\notag\\\\\r\u0026amp;\\quad-\\sum_{i=1}^n\\sum_{k=1}^K\\psi_{ik}\\left[\\frac{m_k^2+s_k^2}2-x_im_k+\\log(\\psi_{ik}) \\right]\\notag\\\\\r\u0026amp;=\\sum_{k=1}^K\\left[\\log(s_k)-\\frac{m_k^2+s_k^2}{2\\sigma^2}\\right] -\\sum_{i=1}^n\\sum_{k=1}^K\\psi_{ik}\\left[\\frac{m_k^2+s_k^2}2-x_im_k+\\log(\\psi_{ik}) \\right]+\\text{const}.\\label{eq:BMGelbo}\r\\end{align}\\]\nNote that all the expectation in the ELBO can be computed in closed form. There are many methods to find a local optimum of .\n\rNewton-Raphson algorithm. It suffices to find the root of \\(\\nabla ELBO(m,s^2,\\psi) = 0\\). Let \\(\\lambda = (m,s^2,\\psi)\\in \\mathbb{R}^{2K+n(K-1)}\\) be a vector of parameters. The Newton-Raphson method uses the iteration\r\\[\\lambda^{(t+1)}=\\lambda^{(t)}-(D^2 ELBO(\\lambda^{(t)}))^{-1} \\nabla ELBO(\\lambda^{(t)}),\\]\rwhere \\(D^2 ELBO(\\lambda^{(t)})\\) is the Hessian matrix.\n\rGradient ascent algorithm. It is a first-order iterative optimization algorithm for finding a local maximum. The iteration is\r\\[\\lambda^{(t+1)}=\\lambda^{(t)} + \\eta_t \\nabla ELBO(\\lambda^{(t)}),\\]\rwhere \\(\\eta_t\u0026gt;0\\) is the learning rate.\n\rCAVI. The iteration is\r\\[\\begin{align}\r\\psi_{t+1,ik} \u0026amp;\\propto \\exp\\{E[\\mu_k]x_i-E[\\mu_k^2]/2\\}\\propto \\exp\\{m_{t,k}x_i-(m_{t,k}^2+s_{t,k}^2)/2\\},\\\\\rm_{t+1,k}\u0026amp;=\\frac{\\sum_{i=1}^n \\psi_{t+1,ik}x_i}{1/\\sigma^2+\\sum_{i=1}^n\\psi_{t+1,ik}}, \\label{eq:miter} \\\\\rs_{t+1,k}^2\u0026amp;=\\frac{1}{1/\\sigma^2+\\sum_{i=1}^n\\psi_{t+1,ik}}, k=1,\\dots,K, i=1,\\dots,n, \\label{eq:siter}\r\\end{align}\\]\rwhere \\(\\psi_{t,\\cdot}, m_{t,\\cdot},s^2_{t,\\cdot}\\) denote the parameters at the step \\(t\\). Note that the algorithm does not need the initial varitional factors for \\(\\psi_i\\).\n\r\rNext, we implement the CAVI algorithm for \\(K=5\\) and \\(n=10^3\\). After a few steps, we can see that the ELBO converges.\nset.seed(1)\r## data generation\rK = 5 # the number of clusters\rn = 1000 # the number of data x_i\rmu = matrix(rnorm(K,mean=0.2,sd=2),ncol = 1) # the means of the K clusters\rc = sample(1:K,n,replace = T) # the indicator\rx = matrix(mu[c]+rnorm(n),ncol = 1)\rplot(density(x),xlab = \u0026#39;x\u0026#39;,main=\u0026#39;kernel density of the data\u0026#39;)\rsig = 1 # hyperparameter for the variance of mu_i\r## ELBO minus a constant\relbo \u0026lt;- function(m,s,psi){\rre = sum(log(s)-(m^2+s^2)/(2*sig^2))- sum(psi%*%(m^2+s^2)/2)+\rt(x)%*%psi%*%m-sum(log(psi)*psi)\rreturn(re)\r}\r## iteration for CAVI\rcavi \u0026lt;- function(m,s){\rpsi = matrix(0,n,K)\rfor(i in 1:n){\rtmp = x[i]*m-(m^2+s^2)/2\rmtmp = max(tmp)\rlogsum = mtmp+log(sum(exp(tmp-mtmp)))\rpsi[i,] = exp(tmp-logsum)\r}\rde = 1/sig^2+colSums(psi)\rm = t(x)%*%psi/de\rs = sqrt(1/de)\rreturn(list(m_next=matrix(m,ncol = 1),s_next=matrix(s,ncol = 1),psi_next=psi))\r}\r## initialization\rnstep = 1e4 # maximal steps\rtolerance = 1e-6 # tolerance for the relative change\rm = matrix(rnorm(K,0,1),K,1) s = matrix(5,K,1)\rELBO = matrix(0,nstep,1)\rstep = 1\rrelative_change = tolerance+1\rwhile(TRUE){\rpara = cavi(m,s)\rm = para$m_next\rs = para$s_next\rpsi = para$psi_next\rELBO[step] = elbo(m,s,psi)\rif(step\u0026gt;1)\rrelative_change = (ELBO[step]-ELBO[step-1])/ELBO[step]\rif(step==nstep | abs(relative_change)\u0026lt;tolerance){ # stopping rule\rbreak\r}\relse{\rstep = step+1\r}\r}\rhatc = apply(psi, 1,which.max)\rcenter = cbind(sort(mu),sort(m))\rcolnames(center) = c(\u0026#39;True Centers\u0026#39;,\u0026#39;VI Means\u0026#39;)\rknitr::kable(center)\r\r\rTrue Centers\rVI Means\r\r\r\r-1.4712572\r-1.5346393\r\r-1.0529076\r-0.9663787\r\r0.5672866\r0.3772178\r\r0.8590155\r0.9019340\r\r3.3905616\r3.4156061\r\r\r\rplot(1:step,ELBO[1:step],type = \u0026#39;b\u0026#39;,xlab = \u0026#39;Step\u0026#39;,ylab=\u0026#39;ELBO\u0026#39;,pch = 16)\rplot(x,col=hatc)\rabline(h=m,col=1:5,lty=2,lwd=2)\r\rExponential Family Conditionals\rAre there specific forms for the local variational\rapproximations in which we can easily compute closed-form conditional ascent updates? Yes, the answer is exponential family conditionals.\nConsider the generic model \\(p(z,x)\\) and suppose each complete conditional is in the exponential family:\r\\[\\begin{equation}\rp(z_j|z_{-j},x) = h(z_j)\\exp\\{\\eta_j(z_{-j},x)^\\top t(z_j)-a(\\eta_j(z_{-j},x))\\},\r\\end{equation}\\]\rwhere \\(t(z_j)\\) is the sufficient statistic, and \\(\\eta_j(z_{-j},x)\\) are the natural parameters.\nConsider mean-field VI for this class of models, where \\(q(z)\\) is given by . The update becomes\r\\[\\begin{align}\rq_j^*(z_j) \u0026amp;\\propto \\exp\\{E_{-j}[\\log p(z_j|z_{-j},x)]\\}\\\\\r\u0026amp;=\\exp\\{\\log h(z_j)+ E_{-j}[\\eta_j(z_{-j},x)^\\top t(z_j)]-E_{-j}[a(\\eta_j(z_{-j},x))]\\}\\\\\r\u0026amp;\\propto h(z_j)\\exp\\{E_{-j}[\\eta_j(z_{-j},x)]^\\top t(z_j)\\}.\r\\end{align}\\]\rThis updata reveals the parametric form of the optimal VI factors. Each one is in the same exponential family as its corresponding complete conditional. Let \\(\\nu_j\\) denote the variational parameter for the \\(j\\)th variational factor. When we update each factor, we set its parameter equal to the expected parameter of the complete conditional,\r\\[\\nu_j = E_{-j}[\\eta_j(z_{-j},x)].\\]\nThere are many popular models fall into this category, including:\n\rBayesian mixtures of exponential family models with conjugate priors.\rHierarchical hidden Markov models.\rKalman filter models and switching Kalman filters.\rMixed-membership models of exponential families.\rFactorial mixtures / hidden Markov models of exponential families.\rBayesian linear regression.\rAny model containing only conjugate pairs and multinomials.\r\rSome popular models do not fall into this category, including:\n\rBayesian logistic regression and other nonconjugate Bayesian generalized linear models.\rCorrelated topic model, dynamic topic model.\rDiscrete choice models.\rNonlinear matrix factorization models.\r\r\rStochastic Gradient Variational Inference\rCAVI may require interating thought the entire dataset at each iteration. As the dataset size grows, each\riteration becomes more computationally expensive (see and ). In more realistic models, the gradient of the ELBO is rarely available in closed form. Stochastic gradient methods (Robbins\rand Monro, 1951) are useful for optimizing an objective function whose gradient can be unbiasedly estimated. Stochastic gradient variational inference (SGVI) becomes an alternative to coordinate ascent. SGVI combines gradients and stochastic optimazation.\nNow we rewrite the ELBO as a function of variational parameters \\(\\lambda\\) (a vector), denoted by \\(\\mathcal L(\\lambda)\\). Let \\(\\nabla_\\lambda\\mathcal L(\\lambda)\\) be the gradient vector of \\(\\mathcal L(\\lambda)\\) w.r.t. \\(\\lambda\\). Gradient ascent algorithm iterates\r\\[\\lambda^{(t+1)}=\\lambda^{(t)} + \\eta_t \\nabla_\\lambda\\mathcal L(\\lambda^{(t)}),\\quad t=0,\\dots,T.\\]\rLet \\(\\widehat{\\nabla_\\lambda\\mathcal L(\\lambda)}\\) be an unibased estimate of \\(\\nabla_\\lambda\\mathcal L(\\lambda)\\). SGVI iterates as follow,\r\\[\\begin{equation}\r\\lambda^{(t+1)}=\\lambda^{(t)} + \\eta_t \\widehat{\\nabla_\\lambda\\mathcal L(\\lambda^{(t)})},\\quad t=1,\\dots,T.\\label{eq:sgdite}\r\\end{equation}\\]\rUnder certain regularity conditions, and the learning rates satisfy the Robbins-Monro conditions\r\\[\\sum_{t=0}^\\infty \\eta_t=\\infty,\\ \\sum_{t=0}^\\infty \\eta_t^2\u0026lt;\\infty,\\]\rthe iterations converge to a local optimum (Robbins and Monro, 1951). Many sequences will satisfy these conditions, for example, \\(\\eta_t=t^{-\\kappa}\\) for \\(\\kappa\\in(0.5,1]\\). Adaptive learning rates are currently\rpopular (Duchi et al., 2011; Zeiler, 2012; Kingma and Ba, 2015; Kingma and Ba, 2015). Adam is a promising method, which is pulished in\n\rKingma, D. and Ba, J. (2015). Adam: A method for stochastic optimization. Proceedings of the International Conference on Learning Representations. (Cited by 43201 on 2020/5/27)\n\rThe name Adam\ris derived from adaptive moment estimation.\nOne important thing is to obtain an unbiased estimate of the gradient \\(\\nabla_\\lambda\\mathcal L(\\lambda)\\).\rThe variational density is now written as \\(q(z;\\lambda)\\). Then,\r\\[\\nabla_\\lambda\\mathcal L(\\lambda) = \\nabla_\\lambda E_q[\\log p(z,x)]-\\nabla_\\lambda E_q[\\log q(z;\\lambda)].\\]\rNote that in some cases (such as mean-field variational family with Gaussian or categorical factors) of variational densities, \\(E_q[\\log q(z;\\lambda)]\\) is analytically solvable, and so does its gradient \\(\\nabla_\\lambda E_q[\\log q(z;\\lambda)]\\). We thus focus on estimating \\(\\nabla_\\lambda E_q[\\log p(z,x)]\\). Suppose that\r\\(\\nabla_\\lambda E_q[\\log p(z,x)]\\) can be written as an expectation, i.e.,\r\\[\\begin{equation}\r\\nabla_\\lambda E_q[\\log p(z,x)]=E[h(z)].\\label{eq:expform}\r\\end{equation}\\]\rThen one can easily find an unbiased estimate of \\(\\nabla_\\lambda\\mathcal L(\\lambda)\\),\r\\[\\begin{equation}\r\\widehat{\\nabla_\\lambda\\mathcal L(\\lambda^{(t)})}=\\frac 1 N \\sum_{i=1}^N h(z_i) -\\nabla_\\lambda E_q[\\log q(z;\\lambda)],\\label{eq:sgd}\r\\end{equation}\\]\rwhere \\(z_i\\) are Monte Carlo samples or quasi-Monte Carlo samples.\nThere are two tricks to obtain the expectation form . Allowing the interchange of integration and differentiation, the score function gradient method\rmakes use of\r\\[\\begin{align}\r\\nabla_\\lambda E_q[\\log p(z,x)]\u0026amp;=\\nabla_\\lambda\\int \\log p(z,x) q(z;\\lambda)d z\\\\\r\u0026amp;= \\int \\log p(z,x) \\nabla_\\lambda q(z;\\lambda)d z\\\\\r\u0026amp;= \\int \\log p(z,x) (\\nabla_\\lambda \\log q(z;\\lambda)) q(z;\\lambda)d z\\\\\r\u0026amp;=E_q[\\log p(z,x) \\nabla_\\lambda \\log q(z;\\lambda)],\r\\end{align}\\]\rachieving the form with \\(h(z)=\\log p(z,x) \\nabla_\\lambda \\log q(z;\\lambda)\\) and \\(z\\sim q(z;\\lambda)\\). On the other hand, the reparameterization method rewrites the expectation \\(E_q[\\log p(z,x)]\\)\ras an expectation w.r.t. a density independently of the parameter \\(\\lambda\\), say, \\(E_{p_0}[\\log p(h(z;\\lambda),x)]\\), where \\(h(z;\\lambda)\\sim q(z;\\lambda)\\) and \\(z\\sim p_0(z)\\) independent of \\(\\lambda\\). As a result,\rby allowing the interchange of integration and differentiation,\r\\[\\begin{align}\r\\nabla_\\lambda E_q[\\log p(z,x)]\u0026amp;=\\nabla_\\lambda E_{p_0}[\\log p(h(z;\\lambda),x)]\\\\\r\u0026amp;= \\nabla_\\lambda \\int \\log (p(h(z;\\lambda),x)) p_0(z) d z\\\\\r\u0026amp;= \\int \\nabla_\\lambda \\log (p(h(z;\\lambda),x)) p_0(z) d z\\\\\r\u0026amp;=E_{p_0}[\\nabla_\\lambda \\log (p(h(z;\\lambda),x))],\r\\end{align}\\]\rachieving the form with \\(h(z)=\\nabla_\\lambda \\log (p(h(z;\\lambda),x))\\) and \\(z\\sim p_0(z)\\).\nThe reparameterization gradient typically exhibits lower variance than the score function gradient but\ris restricted to models where the variational family can be reparametrized via a differentiable mapping. We refer to the article\n\rXu, M., Quiroz, M., Kohn, R., \u0026amp; Sisson, S. A. (2018). Variance reduction properties of the reparameterization trick. arXiv preprint arXiv:1809.10330.\n\rThe convergence of the gradient ascent scheme in tends\rto be slow when gradient estimators have a high variance.\rTherefore, various approaches for reducing the variance of\rboth gradient estimators exist; e.g. control variates,\rRao-Blackwellization, importance sampling as well as quasi-Monte Carlo. For the use of qausi-Monte Carlo in VI, we refer to\n\rBuchholz, A., Wenzel, F., \u0026amp; Mandt, S. (2018). Quasi-monte carlo variational inference. arXiv preprint arXiv:1807.01604.\n\r\rBayesian multinomial logistic regression\rThe famous (Fisher’s or Anderson’s) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.\nLet \\(y_i\\in \\{0,\\dots,K\\}\\) be the categorial data, which relates to \\(x_i = (x_{i1},\\dots,x_{ip})^\\top\\). The multinomial logistic regression is given by\n\\[\\begin{equation}\rP(y_i=k|\\beta) = \\frac{\\exp\\{x_i^\\top \\beta_k\\}}{\\sum_{j=0}^K \\exp\\{x_i^\\top \\beta_j\\}},\\quad k=0,\\dots,K,\r\\end{equation}\\]\nwhere \\(\\beta_k\\in \\mathbb{R}^{p\\times 1}\\) and the parameters are \\(\\beta=(\\beta_1,\\dots,\\beta_K)\\), and we set \\(\\beta_0=0\\) for indentifying the model.\rThe prior we used is \\(\\beta_k\\stackrel{iid}\\sim N(0,\\sigma_0^2I_p),k=1,\\dots,K\\).\rWe treated the designed matrix \\(X\\) as a constant matrix.\nThe variational density we used is Gaussian, i.e., \\(q(\\beta_{ij})\\sim N(\\mu_{ij},\\sigma_{ij}^2)\\). Let \\(\\psi_{ij}=\\log (\\sigma_{ij})\\) so that \\(q(\\beta_{ij})\\sim N(\\mu_{ij},\\exp(2\\psi_{ij})).\\) Now the variational parameters are \\(\\mu_{ij}\\) and \\(\\psi_{ij}\\). We encapsulate them in a vector \\(\\lambda\\). Denote the ELBO by \\(L(\\lambda)\\). We thus have\r\\[\\begin{align}\rL(\\lambda) \u0026amp;= E_q[\\log p(\\beta)] + E_q[\\log p(y|\\theta)] - E_q[\\log q(\\beta)]\\\\\r\u0026amp;=\\sum_{ik}\\left(\\psi_{ik}-\\frac {\\mu_{ik}^2+\\exp(2\\psi_{ik})}{2\\sigma^2_0}\\right) + \\sum_{i=1}^n E_q\\left[\\log \\left(\\frac{\\sum_{k=0}^K\\exp\\{x_i^\\top \\beta_k\\}1\\{y_i=k\\}}{\\sum_{k=0}^K \\exp\\{x_i^\\top \\beta_k\\}}\\right)\\right]+\\text{const}\\\\\r\u0026amp;=L_1(\\lambda)+L_2(\\lambda)+\\text{const}.\r\\end{align}\\]\nIt is easy to see that\r\\[\\frac{\\partial L_1(\\lambda)}{\\partial \\mu_{ik}}=-\\frac{\\mu_{ik}}{\\sigma_0^2},\\quad \\frac{\\partial L_1(\\lambda)}{\\partial \\psi_{ik}}=1-\\frac{\\exp(2\\psi_{ik})}{\\sigma_0^2}.\\]\rThis implies \\(\\nabla_\\lambda L_1(\\lambda)\\) has a close form.\nThe score function gradient for \\(L_2(\\lambda)\\) is given by\r\\[\\nabla_\\lambda L_2(\\lambda)=\\sum_{i=1}^n E_q\\left[\\log \\left(\\frac{\\sum_{k=0}^K\\exp\\{x_i^\\top \\beta_k\\}1\\{y_i=k\\}}{\\sum_{k=0}^K \\exp\\{x_i^\\top \\beta_k\\}}\\right)\\nabla_\\lambda \\log q(\\beta;\\lambda)\\right],\\]\rwhere\r\\[\\frac{\\partial \\log q(\\beta;\\lambda)}{\\partial \\mu_{ik}}=\\frac{\\beta_{ik}-\\mu_{ik}}{\\exp(2\\psi_{ik})},\\ \\frac{\\partial \\log q(\\beta;\\lambda)}{\\partial \\psi_{ik}}=\\frac{(\\beta_{ik}-\\mu_{ik})^2}{\\exp(2\\psi_{ik})}-1.\\]\nWe now rewrites the expectation \\(L_2(\\lambda)\\) as\r\\[\\begin{align}\rL_2(\\lambda)\u0026amp;=\\sum_{i=1}^n E_q\\left[\\log \\left(\\frac{\\sum_{k=0}^K\\exp\\{x_i^\\top \\beta_k\\}1\\{y_i=k\\}}{\\sum_{k=0}^K \\exp\\{x_i^\\top \\beta_k\\}}\\right)\\right]\\\\\r\u0026amp;=\\sum_{i=1}^n E\\left[\\log \\left(\\frac{\\sum_{k=0}^K\\exp\\{x_i^\\top (\\mu_{\\cdot k}+\\text{diag}(\\exp(\\psi_{\\cdot k}))z_k)\\}1\\{y_i=k\\}}{\\sum_{k=0}^K \\exp\\{x_i^\\top (\\mu_{\\cdot k}+\\text{diag}(\\exp(\\psi_{\\cdot k}))z_k)\\}}\\right)\\right],\\\\\r\\end{align}\\]\rwhere \\(z_k\\stackrel{iid}\\sim N(0,I_p)\\).\rThe\rreparameterization gradient is given by\r\\[\\begin{align}\r\\nabla_\\lambda L_2(\\lambda)\u0026amp;= \\sum_{i=1}^n E\\left[\\nabla_\\lambda\\log \\left(\\frac{\\sum_{k=0}^K\\exp\\{x_i^\\top (\\mu_{\\cdot k}+\\text{diag}(\\exp(\\psi_{\\cdot k}))z_k)\\}1\\{y_i=k\\}}{\\sum_{k=0}^K \\exp\\{x_i^\\top (\\mu_{\\cdot k}+\\text{diag}(\\exp(\\psi_{\\cdot k}))z_k)\\}}\\right)\\right]\\\\\r\u0026amp;=:\\sum_{i=1}^n E[\\nabla_\\lambda h_{i}(z;\\lambda)].\r\\end{align}\\]\nwhere\r\\[\\begin{align}\r\\frac{\\partial h_{i}(z;\\lambda)}{\\mu_{jk}}\u0026amp;= x_{ij}1\\{y_i=k\\} -\\frac{x_{ij}\\exp\\{x_i^\\top (\\mu_{\\cdot k}+\\text{diag}(\\exp(\\psi_{\\cdot k}))z_k)\\}}{\\sum_{k=0}^K \\exp\\{x_i^\\top (\\mu_{\\cdot k}+\\text{diag}(\\exp(\\psi_{\\cdot k}))z_k)\\}},\r\\end{align}\\]\r\\[\\begin{align}\r\\frac{\\partial h_{i}(z;\\lambda)}{\\psi_{jk}}\u0026amp;=x_{ij}z_{jk}\\exp(\\psi_{jk})1\\{y_i=k\\}-\\frac{x_{ij}z_{jk}\\exp(\\psi_{jk})\\exp\\{x_i^\\top (\\mu_{\\cdot k}+\\text{diag}(\\exp(\\psi_{\\cdot k}))z_k)\\}}{\\sum_{k=0}^K \\exp\\{x_i^\\top (\\mu_{\\cdot k}+\\text{diag}(\\exp(\\psi_{\\cdot k}))z_k)\\}}.\r\\end{align}\\]\rAs a result,\n\rFigure 1: The species are Iris setosa, versicolor, and virginica.\r\r\r\r\rSepal.Length\rSepal.Width\rPetal.Length\rPetal.Width\rSpecies\r\r\r\r1\r5.1\r3.5\r1.4\r0.2\rsetosa\r\r2\r4.9\r3.0\r1.4\r0.2\rsetosa\r\r3\r4.7\r3.2\r1.3\r0.2\rsetosa\r\r51\r7.0\r3.2\r4.7\r1.4\rversicolor\r\r52\r6.4\r3.2\r4.5\r1.5\rversicolor\r\r53\r6.9\r3.1\r4.9\r1.5\rversicolor\r\r101\r6.3\r3.3\r6.0\r2.5\rvirginica\r\r102\r5.8\r2.7\r5.1\r1.9\rvirginica\r\r103\r7.1\r3.0\r5.9\r2.1\rvirginica\r\r\r\rWe next show the results for the iris data with the score function gradient based Adam algorithm.\n\r## data generation\rset.seed(0)\rdata(iris)\rn \u0026lt;- nrow(iris)\rp \u0026lt;- ncol(iris)\rK \u0026lt;- nlevels(iris$Species)\rX \u0026lt;- model.matrix(Species ~ ., data=iris) # design matrix\rY \u0026lt;- model.matrix(~ Species - 1, data=iris)\rsigma0 = 10\relbo_hat\u0026lt;- function(mu,psi,N){\rL1 = sum(psi-(mu^2+exp(2*psi))/(2*sigma0^2))\rbeta = matrix(0,p,K) # the first column is zero est = matrix(0,N,1)\rfor (i in 1:N){\rbeta[,-1] = mu + exp(psi) * matrix(rnorm(p*(K-1)),p,K-1)\rtmp = exp(X%*%beta)\rden = rowSums(tmp)\rnum = rowSums(tmp*Y)\rest[i] = sum(log(num/den))\r}\rreturn(mean(est)+L1)\r}\rscore_fun_gradient \u0026lt;- function(mu,psi,N){\rdmu = -mu/sigma0^2\rdpsi = 1-exp(2*psi)/sigma0^2\rbeta = matrix(0,p,K) # the first column is zero for (i in 1:N){\rbeta[,-1] = mu + exp(psi) * matrix(rnorm(p*(K-1)),p,K-1)\rtmp = exp(X%*%beta)\rden = rowSums(tmp)\rnum = rowSums(tmp*Y)\rsumlog = sum(log(num/den))\rdmu = dmu + sumlog*(beta[,-1]-mu)/exp(2*psi)/N\rdpsi = dpsi + sumlog*((beta[,-1]-mu)^2/exp(2*psi)-1)/N\r}\rreturn(list(dmu=-dmu,dpsi=-dpsi)) # return negative gradient for adapting the Adam\r}\r#Adam: See the paper \u0026#39;ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION\u0026#39;\ralpha = 0.1\rbeta1 = 0.9\rbeta2 = 0.999\reps = 1e-8\r#initial parameters\rmut = matrix(0,p,K-1)\rpsit = matrix(0,p,K-1)\rmu_mt = matrix(0,p,K-1) #first moment\rpsi_mt = matrix(0,p,K-1)\rmu_vt = matrix(0,p,K-1) #second moment\rpsi_vt = matrix(0,p,K-1)\rT = 500\rNg = 100 #sample size for gradient\rNelbo = 10000 #sample size for estimating elbo\relbo = matrix(0,T,1)\rfor(t in 1:T){\rgt = score_fun_gradient(mut,psit,Ng)\rmu_mt = beta1*mu_mt + (1-beta1)*gt$dmu\rmu_vt = beta2*mu_vt + (1-beta2)*gt$dmu^2\rhat_mu_mt = mu_mt/(1-beta1^t)\rhat_mu_vt = mu_vt/(1-beta2^t)\rmut = mut - alpha*hat_mu_mt/(sqrt(hat_mu_vt)+eps)\rpsi_mt = beta1*psi_mt + (1-beta1)*gt$dpsi\rpsi_vt = beta2*psi_vt + (1-beta2)*gt$dpsi^2\rhat_psi_mt = psi_mt/(1-beta1^t)\rhat_psi_vt = psi_vt/(1-beta2^t)\rpsit = psit - alpha*hat_psi_mt/(sqrt(hat_psi_vt)+eps) #update the state\relbo[t] = elbo_hat(mut,psit,Nelbo)\r}\rplot(elbo,type=\u0026#39;b\u0026#39;,xlab = \u0026#39;Iteration\u0026#39;,ylab=\u0026quot;ELBO\u0026quot;,pch=16)\r\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"7d333683bccc71a3910f7eeb09d00491","permalink":"/zh/courses/bayes/vi/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/vi/","section":"courses","summary":"This note is adapted to the paper entitled “Variation Inference: A Review for Statisticans” by Blei et al. (2017).\nBasic ideas of VI\rLet \\(z=z_{1:m}\\) be the latent variables that govern the distribution of the data (observations) \\(x=x_{1:n}\\).","tags":null,"title":"变分推断","type":"docs"},{"authors":null,"categories":null,"content":"\rIntroduction to Bayesian computation\rThe goals are to estimate\n\rthe posterior distribution \\(p(\\theta|y)\\propto p(\\theta)p(y|\\theta)\\)\n\rthe posterior predictive distribution\r\\[p(\\tilde y|y) = \\int p(\\tilde y|\\theta)p(\\theta|y)d \\theta =E[p(\\tilde y|\\theta)|y]\\]\n\r\rWe are therefore insterested in estimating the posterior expectation\r\\[\\mu=E[h(\\theta)|y]=\\int h(\\theta)p(\\theta|y)d \\theta\\]\n\rmoments: \\(h(\\theta)=\\theta^k\\)\rprobability: \\(h(\\theta)=1_A(\\theta)\\), \\(A\\subseteq \\Theta\\)\rpredictive density: \\(h(\\theta)=p(\\tilde y|\\theta)\\) for fixed \\(\\tilde y\\)\r\r\rMonte Carlo methods\rSuppose we can simulate \\(\\theta^{(1)},\\dots,\\theta^{(N)}\\sim p(\\theta|y)\\) independently. Monte Carlo (MC) esimate is then the sample average:\r\\[\\hat{\\mu}_N = \\frac1N\\sum_{i=1}^N h(\\theta^{(i)})\\]\n\rLLN: \\(\\hat\\mu_N\\to \\mu\\) w.p.1 as \\(N\\to \\infty\\)\rCLT: \\(\\hat\\mu_N-\\mu=O_p(N^{-1/2})\\)\r\rTraditional quadrature rules’ have error rate \\(O(N^{-r/d})\\), where \\(r\\ge 1\\) depends on the smoothness of the functions, and \\(d\\) is the dimension of \\(\\theta\\). This suffers the curse of dimensionality.\nMC has an error rate \\(O(N^{-1/2})\\) independently of the smoothness and the dimension of the functions. The task is to simulate iid samples \\(\\theta^{(i)}\\sim p(\\theta|y)\\).\n\rRandom number generators\rWe start with a pseudo-random number generator:\r\\[u_1,\\dots,u_n,\\dots\\stackrel{iid}\\sim U(0,1)\\]\n\rMersenne Twister by Matsumoto \u0026amp; Nishimura (1998), whose period is \\(2^{19937}-1\u0026gt;10^{6000}\\)\rRngStreams by L’Ecuyer, Simard, Chen, Kelton (2002)\r\rThey aren’t really uniform random, but good ones are close enough.\n\rNon-uniform random variables\rSome common distributions (such as Normal, exponential, binomial, Poisson etc.) are already in some scientific softwares (R, Python, Matlab, Julia, Mathematica, etc.)\nWe are now concerned with a general distribution. Principled approaches are\n\rinversion\racceptance-rejection\r\r\rInversion\rLet \\(F(x)\\) be the CDF of the distribution of interest. We can simulate the distribution via iid uniforms \\(U_1,\\dots,U_N\\stackrel{iid}\\sim U(0,1)\\):\n\\[X_i=F^{-1}(U_i),i=1,\\dots,N\\]\n\r\\(F^{-1}\\) is the inverse of the CDF \\(F\\), definited by\r\\[F^{-1}(u)=\\inf\\{x\\in\\mathbb{R}|F(x)\\ge u\\}\\]\n\rit is easy to see that \\(X_i\\stackrel{iid}\\sim F\\)\n\r\r\rInversion: examples\rGaussian\r\\[Z=\\Phi^{-1}(U)\\sim N(0,1)\\]\n\\[X=\\mu+\\sigma\\Phi^{-1}(U) \\sim N(\\mu,\\sigma^2)\\]\n\rExponential\r\\[X= -\\frac 1\\lambda \\log (1-U)\\sim Exp(\\lambda)\\]\n\rBernoulli\r\\[X=1\\{U\\le p\\}\\sim Bin(1,p)\\]\n\r\rMultivariate inverse transformation\r\rlet \\(F(x_1,\\dots,x_d)\\) be the PDF of \\(X_1,\\dots,X_d\\)\rlet \\(F_i(x_i)\\) be the marginal distribution of \\(X_i\\)\rfor \\(i=2,\\dots,d\\), let \\(F_i(x_i|x_1,\\dots,x_{i-1})\\) be the conditional CDF\r\rThe multivariate inverse transformation is proposed by Rosenblatt (1952), which simulates the components \\(X_i\\) recursively, i.e.,\n\\[X_1=F_1^{-1}(U_1)\\]\r\\[X_i=F_i^{-1}(U_i|X_1,\\dots,X_{i-1}),\\ i=2,\\dots,d\\]\n\rthe output has the destribution \\(F\\)\rthe order of simulating the components can be arbitrary\rthe critical issue is to know the conditional CDFs in advance\r\r\rAcceptance-rejection\r\rsuppose the target distrubtion is \\(f(x)\\) with the support \\(\\mathcal{X}\\)\rwe can sample \\(Y\\sim g\\), where \\(g\\) is another density satisfying: there exists \\(M\u0026gt;0\\) such that\r\\[\\frac{f(x)}{g(x)}\\le M\\ \\forall x\\in \\mathcal{X}\\]\rwe can compute \\(f(x)/g(x)\\)\r\rThe algorithm goes below\n\rStep 1: simulate \\(Y\\sim g\\)\n\rStep 2: accept \\(Y\\) as a draw from \\(f\\) with probability \\(f(Y)/(Mg(Y))\\). If the draw is rejected, return to Step 1.\n\rStep 2’: simulate \\(U\\sim U(0,1)\\)\r\\[\r\\begin{cases}\r\\text{accept } Y \u0026amp; U\\le f(Y)/(Mg(Y))\\\\\r\\text{go to Step 1 }\u0026amp; else\r\\end{cases}\r\\]\n\r\r\rAcceptance-rejection\r\rthe acceptance probability: \\[E[f(Y)/(Mg(Y))]=\\frac 1 M\\]\rwe may choose the smallest \\(M\\) such that \\(f(x)\\le Mg(x)\\) for all \\(x\\in\\mathcal{X}\\)\r\r\rAcceptance-rejection for Bayesian computation\r\rthe target density\r\\[p(\\theta|y)=\\frac{p(\\theta)p(y|\\theta)}{p(y)}\\]\n\rthe constant \\(p(y)\\) is unknown\n\rthe AR algorithm works well if taking \\(f(\\theta)=p(\\theta)p(y|\\theta)\\)\rand using proposal density \\(\\propto g(\\theta)\\) with\r\\[\\frac{p(\\theta)p(y|\\theta)}{g(\\theta)}\\le M\\]\n\r\r\rExample: Gamma distribution\r\r\\(Gamma(\\alpha,\\lambda)\\), \\(\\alpha\u0026gt;0\\) is the shape, \\(\\lambda\u0026gt;0\\) is the rate\n\rdensity\n\r\r\\[f(x) = \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\lambda x}1\\{x\u0026gt; 0\\}\\]\n\\[Gamma(\\alpha,\\lambda)\\stackrel{d}{=}\\frac 1 \\lambda Gamma(\\alpha,1)\\]\n\\[Gamma(\\alpha,1)\\stackrel{d}{=}U(0,1)^{1/\\alpha}Gamma(\\alpha+1,1)\\]\n\rso our target is \\(Gamma(\\alpha,1)\\) with \\(\\alpha\u0026gt;1\\). For this case, the density is bounded.\n\rthe proposal\r\\[g(x)=?\\]\n\r\r\rGamma density\r\rAhrens and Dieter (1974) took proposals from a density that combines a\rGaussian density in the center and an exponential density in the right tail.\n\rMarsaglia and Tsang (2000) present an AR algorithm from a truncated\r\\(N(0,1)\\)\n\r\r\rExample: Beta distribution\r\r\\(Beta(\\alpha,\\beta)\\) density\r\\[f(x)=\\frac{\\Gamma(\\alpha,\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}1\\{0\u0026lt;x\u0026lt;1\\}\\]\n\rgenerate a Beta from two independent Gammas\r\\[Beta(\\alpha,\\beta)\\stackrel{d}{=}\\frac{Gamma(\\alpha,\\lambda)}{Gamma(\\alpha,\\lambda)+Gamma(\\beta,\\lambda)}\\]\n\rfor \\(\\alpha\u0026gt;1\\) and \\(\\beta\u0026gt;1\\), the beta density is unimodal and achieves its maximum at \\(x^*=(\\alpha-1)/(\\alpha+\\beta-2)\\)\n\r\r\rBeta density\r\rProposal distribution: \\(U(0,1)\\)\r\\(M=f(x^*)\\)\raccept \\(U\\sim U(0,1)\\) with probability \\(f(U)/M\\)\r\r\rBeta generator: R code\rmyBeta \u0026lt;- function(n,alpha,beta){\rif(alpha\u0026lt;=1 | beta\u0026lt;=1)\rstop(\u0026quot;alpha, beta cannot be \u0026lt;= 1\u0026quot;)\rM = dbeta((alpha-1)/(alpha+beta-2),alpha,beta)\rx = rep(0,n)\rfor(i in 1:n){\rwhile (TRUE){\rU = runif(1)\rif(dbeta(U,alpha,beta)\u0026gt;= M*runif(1)){\rx[i] = U\rbreak\r}\r}\r}\rreturn(x)\r}\r\rSimulation results\r\rTable 1: \r\r\rmean\rsd\r\r\r\rmyBeta\r0.4001780\r0.1968478\r\rdbeta\r0.3996059\r0.2000705\r\rtrue values\r0.4000000\r0.2000000\r\r\r\r\rImportance Sampling\r\rthe target is to estimate \\(\\mu=E_f[h(X)]\\) w.r.t. the density \\(f(x)\\)\n\rthe proposal density \\(g(x)\\): \\(g(x)\u0026gt;0\\) whenever \\(h(x)f(x)\u0026gt;0\\)\r\\[\\mu=\\int h(x)f(x)dx=\\int h(x)\\frac{f(x)}{g(x)}g(x)dx=E_g[h(X)f(X)/g(X)]\\]\n\r\\(f(x)/g(x)\\) called the likelihood ratio (LR)\n\r\rThe IS algorithm goes below\n\rStep 1: simulate \\(n\\) samples \\(X_1,\\dots,X_n\\) from \\(g(x)\\)\rStep 2: compute the sample average:\r\\[\\hat{\\mu}_{IS}=\\frac 1N\\sum_{i=1}^N \\frac{h(X_i)f(X_i)}{g(X_i)}\\]\r\r\rChoosing the proposal\r\\[Var[\\hat{\\mu}_{IS}] = \\frac{\\sigma^2_g}{N}\\]\n\\[\\sigma^2_g = \\int \\left(\\frac{h(x)f(x)}{g(x)}-\\mu\\right)^2g(x)d x=\\int\\frac{(h(x)f(x)-\\mu g(x))^2}{g(x)}dx\\]\n\rif \\(g(x)=h(x)f(x)/\\mu\\) and \\(h\\ge 0\\), then we have the optimal case \\(\\sigma^2_g=0\\)\rbut unattainable: \\(\\mu\\) is unknown constant\rwe may find \\(g(x)\\approx h(x)f(x)/\\mu\\)\r\r\rThe weight function\r\rlet \\(w(x)=f(x)/g(x)\\) be the LR\r\\[\\sigma^2_g =\\int \\frac{(hf)^2}{g}dx -\\mu^2\\]\r\r\\[\\int \\frac{(hf)^2}{g}dx=E_f[w(X)h(X)^2]=E_g[w(X)^2h(X)^2]\\]\n\rif \\(w(x)\\) is bounded, then \\(\\sigma^2_g\\) is bounded\rif \\(w(x)\\) is unbounded, then \\(\\sigma^2_g\\) may be unbounded (the worst case!)\r\r\rSelf-normalized IS (SNIS)\rWhat if we cannot compute \\(f/g\\)? Suppose that\r\\[f(x)=c_f\\tilde{f}(x),\\ g(x)=c_g\\tilde{g}(x)\\]\nand we can compute \\(\\tilde f,\\tilde g\\) but not the constants \\(c_f,c_g\\). Then we use\n\\[\\hat{\\mu}_{SNIS}= \\frac{\\frac 1 N\\sum_{i=1}^nh(X_i)\\tilde{f}(X_i)/\\tilde{g}(X_i)}{\\frac 1 N\\sum_{i=1}^n\\tilde{f}(X_i)/\\tilde{g}(X_i)}\\]\nor, equivalently,\n\\[\\hat{\\mu}_{SNIS}= \\frac{\\frac 1 N\\sum_{i=1}^Nh(X_i){f}(X_i)/{g}(X_i)}{\\frac 1 N\\sum_{i=1}^N{f}(X_i)/{g}(X_i)}=\\frac{\\frac 1 N\\sum_{i=1}^Nh(X_i)w(X_i)}{\\frac 1 N\\sum_{i=1}^Nw(X_i)}\\]\n\rVariance of SNIS\r\rTaylor expansions\r\\[f(\\bar X,\\bar Y)\\approx f(\\mu_1,\\mu_2)+f_x(\\mu_1,\\mu_2)(\\bar X-\\mu_1)+f_y(\\mu_1,\\mu_2)(\\bar Y-\\mu_2)\\]\r\r\\[E[f(\\bar X,\\bar Y)]\\approx f(\\mu_1,\\mu_2)\\]\n\\[Var[f(\\bar X,\\bar Y)]\\approx f_x^2Var[\\bar X]+f_y^2Var[\\bar Y]+2f_xf_yCov(\\bar X,\\bar Y)\\]\n\rfor \\(f(x,y)=x/y\\), \\(f_x=1/y,f_y=-x/y^2\\)\r\\[Var[f(\\bar X,\\bar Y)]\\approx \\frac{\\sigma_X^2}{N\\mu_2^2}+\\frac{\\mu_1^2\\sigma_Y^2}{N\\mu_2^4}-\\frac{2\\mu_1}{N\\mu_2^3}Cov(X,Y)\\]\n\r\\(Var[\\hat{\\mu}_{SNIS}]\\approx \\frac{1}{N}E_g[w(X)^2(h(X)-\\mu)^2]\\)\n\r\\(Var[\\hat{\\mu}_{IS}]= \\frac{1}{N}E_g[(h(X)w(X)-\\mu)^2]\\)\n\r\r\rOptimal SNIS\r\rSNIS: \\(g_{opt}(x)\\propto f(x)|h(x)-\\mu|\\)\n\rIS: \\(g_{opt}(x)\\propto f(x)|h(x)|\\)\n\r\r\rEffective sample size\r\rUnequal weighting raises variance, see, Kong (1992), Evans and Swartz (1995)\n\rfor iid \\(Y_i\\) with variance \\(\\sigma^2\\) and fixed \\(w_i\\ge 0\\),\r\\[Var\\left(\\frac{\\sum_{i}w_iY_i}{\\sum_iw_i}\\right)=\\frac{\\sum_iw_i^2\\sigma^2}{(\\sum_iw_i)^2}=\\frac{\\sigma^2}{N_{eff}}\\]\n\r\rwhere the effective sample size \\(N_{eff}\\) is defined as\n\\[N_{eff} = \\frac{(\\sum_{i=1}^Nw_i)^2}{\\sum_{i=1}^Nw_i^2}\\in [1,N]\\]\n\r\\(N_{eff}\\) is small if there are few extremely high weights which would unduly influence the distribution\n\rfor equal weights, we have \\(N_{eff}=N\\)\n\r\r\rExample 1\rSuppose the posterior distribution is \\(N(\\mu,\\sigma^2)\\), the proposal distribution is \\(t_3(\\mu,\\sigma^2)\\). Consider \\(\\mu=\\sigma=2\\).\n\rExample 1\r## [1] \u0026quot;Effective sample size is 9178 / 10000\u0026quot;\r\rTable 2: \r\r\rn=100\rn=1000\rn=10000\rexact_value\r\r\r\rMean\r2.214328\r2.011347\r1.945335\r2\r\rVariance\r3.069694\r3.688183\r4.052519\r4\r\r\r\r\rExample 2\rSuppose the posterior distribution is \\(t_3(\\mu,\\sigma^2)\\), the proposal distribution is \\(N(\\mu,\\sigma^2)\\).\n## [1] \u0026quot;Effective sample size is 6180 / 10000\u0026quot;\r\rTable 3: \r\r\rn=100\rn=1000\rn=10000\rexact_value\r\r\r\rMean\r1.802681\r1.784954\r2.019707\r2\r\rVariance\r4.630305\r6.931088\r6.875331\r12\r\r\r\r\rIS vs acceptance rejection\r\rAcceptance-rejection requires bounded LR \\(f/g\\)\n\rWe also have to know a bound\n\rIS and SNIS require us to keep track of weights\n\rPlain IS requires normalized \\(f/g\\)\n\rAcceptance-rejection samples cost more (due to rejections)\n\r\r\rIS for rare events\r\rrare events:\r\\[h(x)=1_A(x), \\mu = E_f[h(x)]=\\int_A f(x) dx=\\epsilon\\approx 0\\]\n\rcoefficient of variation of \\(\\hat{\\mu}\\)\r\\[cv:=\\frac{\\sigma/\\sqrt{N}}{\\mu}=\\frac{\\sqrt{\\epsilon(1-\\epsilon)}}{\\sqrt{n}\\epsilon}\\approx \\frac{1}{\\sqrt{n\\epsilon}}\\]\n\rto get \\(cv=0.1\\) takes \\(N\\ge 100/\\epsilon\\), e.g., \\(\\epsilon = 10^{-5}\\), then \\(N\\ge 10^7\\)\n\rTaking \\(X\\sim f\\) does not get enough data from the important region \\(A\\).\n\rGet more data from \\(A\\) (from a proper proposal \\(g(x)\\)), and then correct the bias (the LR function)\n\r\r\rChanging a parameter\r\rnorminal distribution \\(p(x;\\theta_0)\\), \\(\\theta_0\\in\\Theta\\)\n\rproposal distribution \\(p(x;\\theta)\\), \\(\\theta\\in\\Theta\\)\n\restimator\r\\[\\hat\\mu_\\theta=\\frac{1}{N}\\sum_{i=1}^N h(X_i) \\frac{p(X_i;\\theta_0)}{p(X_i;\\theta)}\\]\n\r\rThe importance ratio often simplifies, e.g., in exponential families.\n\rExponential tilting\rMany important distributions can be written in the form\r\\[p(x;\\theta) = a(\\theta)\\exp[\\eta(\\theta)^\\top T(x)]b(x), \\theta\\in \\Theta\\]\n\\[\\hat\\mu_\\theta=\\frac{a(\\theta_0)}{a(\\theta)}\\frac{1}{N}\\sum_{i=1}^N h(X_i) \\exp[(\\eta(\\theta_0)-\\eta(\\theta))^\\top T(X_i)]\\]\n\r\\(\\eta(\\theta)\\) is the natrual parameter\n\rThis is called the ‘exponential twisting’.\n\rThe goal is to choose \\(\\theta\\in\\Theta\\) such that \\(Var[\\hat\\mu_\\theta]\\) is minimized.\n\r\r\rA simple example\r\rnorminal distribution \\(p(x;\\theta_0)=N(x;0,1)\\)\n\rproposal distribution \\(p(x;\\theta)=N(x;\\theta,1)\\), \\(\\theta\\in\\mathbb{R}\\)\n\rtarget function \\(h(x) = 1\\{x\u0026gt;c\\}\\), for large \\(c\u0026gt;0\\), \\(\\mu=E[h(X)]=1-\\Phi(c)\\approx 0\\)\n\rIS estimator\r\\[\\hat\\mu_\\theta=\\frac{1}{N}\\sum_{i=1}^N h(X_i) \\frac{N(X_i;0,1)}{N(X_i;\\theta,1)}=\\frac{1}{N}\\sum_{i=1}^N h(X_i) e^{-\\frac{2\\theta X_i-\\theta^2}{2}}\\]\n\rIS variance \\(Var[\\hat\\mu_\\theta]=\\sigma^2_\\theta/N\\)\r\\[\\sigma^2_\\theta=\\frac{e^{\\theta^2}}{\\sqrt{2\\pi}}\\int_c^\\infty e^{-\\frac{(x+\\theta)^2}{2}}dx-\\mu^2=e^{\\theta^2}[1-\\Phi(c+\\theta)]-\\mu^2\\]\n\rthe optimal parameter \\(\\theta^*=\\arg \\min_{\\theta\\in \\mathbb{R}} e^{\\theta^2}[1-\\Phi(c+\\theta)]\\)\n\r\r\rThe effect of different parameters\r## [1] \u0026quot;the threshold c = 3\u0026quot;\r## [1] \u0026quot;the true value is 0.00135\u0026quot;\r## [1] \u0026quot;the optimal theta is 3.155\u0026quot;\r## [1] \u0026quot;variance reduction factor is 222\u0026quot;\r\rApplications in Computational Finance\r\rP. Glasserman, P. Heidelberger, and P. Shahabuddin. Asymptotically optimal importance\rsampling and stratification for pricing path-dependent options. Mathematical Finance, 9\r(2):117–152, 1999.\n\rP. Glasserman, P. Heidelberger, and P. Shahabuddin. Variance reduction techniques for\restimating value-at-risk. Management Science, 46(10):1349–1364, 2000.\n\rP. Glasserman, J. Li. Importance Sampling for Portfolio Credit Risk. Management Science, 51(11):1643–1656, 2005.\n\rXie, Fei, Zhijian He, and Xiaoqun Wang. An Importance Sampling-Based Smoothing Approach for Quasi-Monte Carlo Simulation of Discrete Barrier Options. European Journal of Operational Research, October 17, 2018.\rhttps://doi.org/10.1016/j.ejor.2018.10.030\n\r\r\rImportance Sampling for Portfolio Credit Risk\rOur interest centers on the distribution of losses\rfrom default over a fixed horizon.\n\r\\(m\\): number of obligors\n\r\\(Y_k\\): default indicator for \\(k\\)th obligor, \\(Y_k=1\\) denotes the default; \\(Y_k=0\\) otherwise\n\r\\(p_k\\): marginal probability that \\(k\\)th obligor defaults\n\r\\(c_k\\): loss resulting from default of \\(k\\)th obligor\n\r\\(L=c_1Y_1+\\dots+c_mY_m\\): total loss from defaults\n\r\rOur goal is to estimate tail probabilities \\(P(L\u0026gt;x)\\), especially at large values of \\(x\\)\n\rNormal copula model\rIn the normal copula model, dependence\ris introduced through a multivariate normal vector \\(X_1,\\dots,X_m\\) of latent variables. Each default indicator is represented as\r\\[Y_k = 1\\{X_k\u0026gt; x_k\\},\\ k=1,\\dots,m.\\]\r\\[X_k = a_{k1}Z_1+\\dots+a_{kd}Z_d+b_k\\epsilon_k\\]\n\r\\(x_k\\) are chosen to match \\(P(X_k\u0026gt;x_k)=p_k\\)\n\r\\(Z_1,\\dots,Z_d\\stackrel{iid}{\\sim} N(0,1)\\) are systematic risk factors\n\r\\(\\epsilon_k\\stackrel{iid}{\\sim} N(0,1)\\) is an idiosyncratic risk\n\r\\(a_{k1},\\dots,a_{kd}\\) are the loading factors satisfying \\(\\sum_{j=1}^d a_{kj}^2\\le 1\\)\n\r\\(b_k=\\sqrt{1-\\sum_{j=1}^d a_{kj}^2}\\) so that \\(X_k\\sim N(0,1)\\)\n\r\r\rIS for independent obligors\rConsider the simple case of independent obligors: \\(a_{ij}=0,\\ b_k=1\\), i.e., \\(Y_k\\sim Bin(1,p_k)\\) independently. The idea is to replace each default probability \\(p_k\\) by some other default probability \\(q_k\\), the basic IS identity is\r\\[P(L\u0026gt;x)= \\tilde{E}\\left[1\\{L\u0026gt;x\\}\\prod_{k=1}^m\\frac{p_k^{Y_k}(1-p_k)^{1-Y_k}}{q_k^{Y_k}(1-q_k)^{1-Y_k}}\\right]\\]\nExponential Twisting: Glasserman and Li (2005) chooses\r\\[q_{k,\\theta} = \\frac{p_ke^{\\theta c_k}}{1+p_k(e^{\\theta c_k}-1)}\\]\n\rThe original probabilities correspond to \\(\\theta=0\\)\n\rif \\(\\theta\u0026gt;0\\), this does indeed increase the default\rprobabilities; a larger exposure \\(c_k\\) results in a greater\rincrease in the default probability.\n\r\r\rChoosing the optimal parameter\rThe LR is reduced to\r\\[\\prod_{k=1}^m\\frac{p_k^{Y_k}(1-p_k)^{1-Y_k}}{q_k^{Y_k}(1-q_k)^{1-Y_k}}=\\exp(-\\theta L+\\psi(\\theta))\\]\nwhere\r\\[\\psi(\\theta)=\\log E[e^{\\theta L}]=\\sum_{k=1}^m \\log(1+p_k(e^{\\theta c_k}-1))\\]\ris the cumulant generating function (CGF) of L.\nThe optimal parameter is\r\\[\\theta^* = \\arg \\min_{\\theta\\ge 0} \\{M_2(\\theta)=E_\\theta[1\\{L\u0026gt;x\\}e^{-2\\theta L+2\\psi(\\theta)}]\\}\\]\n\rChoosing the sub-optimal parameter\rObserve that for \\(\\theta\\ge 0\\),\r\\[M_2(\\theta)\\le e^{-2\\theta x+2\\psi(\\theta)}\\]\nMinimizing \\(M_2(\\theta)\\) is difficult, but minimizing\rthe upper bound is easy:\r\\[\\theta_x = \\arg \\min_{\\theta\\ge 0}e^{-2\\theta x+2\\psi(\\theta)}=\\arg \\max_{\\theta\\ge 0} \\{\\theta x-\\psi(\\theta)\\}\\]\nThe function \\(\\psi(\\theta)\\) is strictly convex and passes through the origin, so the maximum\ris attained at\r\\[\\theta_x = \\begin{cases}\r\\text{unique solution to }\\psi\u0026#39;(\\theta)=x,\\ \u0026amp;x\u0026gt;\\psi\u0026#39;(0)\\\\\r0,\\ \u0026amp;x\\le \\psi\u0026#39;(0).\r\\end{cases}\r\\]\n\rfor the first case, \\(E_{\\theta_x}[L]=\\psi\u0026#39;(\\theta_x)=x\\), thus, we have shifted the distribution of L so that x is now its mean.\n\rfor the second case, the event \\(\\{L\u0026gt;x\\}\\) is not rare, so we do not change the probabilities.\n\r\r\rDependent Obligors: Conditional Importance Sampling\rFor general factor models, \\(Y_k\\) are dependent; but they are independent conditinal on the systematic risk factors \\(Z_1,\\dots,Z_d\\). So we can apply the so-called conditional IS.\n\rStep 1: simulate \\(Z_1,\\dots,Z_d\\sim N(0,1)\\) and compute the default probability\r\\(p_k=p_k(Z_1,\\dots,Z_d)\\)\n\rStep 2: for simulated \\(p_k\\), obtain the twisting parameter \\(\\theta_x=\\theta_x(Z_1,\\dots,Z_d)\\)\n\rStep 3: compute the LR for the \\(\\theta_x\\)\n\rStep 4: repeat Steps 1–4 \\(N\\) times and then obtain the final IS estimate\n\r\r\rNumerical results\rThe numerical results were reported in Glasserman and Li (2005).\n\r\\(21\\)-factor model with \\(m=1000\\) obligors\r\\(p_k = 0.01(1+\\sin(16\\pi k/m))\\)\r\\(c_k=(\\lceil5k/m\\rceil)^2\\)\rVRF = “Variance Reduction Factor”\r\r\r\r\\(x\\)\r\\(P(L\u0026gt;x)\\)\rVRF\r\r\r\r10,000\r0.0114\r33\r\r14,000\r0.0065\r53\r\r18,000\r0.0037\r83\r\r22,000\r0.0021\r125\r\r30,000\r0.0006\r278\r\r40,000\r0.0001\r977\r\r\r\r\rExtensions\rThe defual indicators\n\\[Y_k=1\\{X_k\u0026gt;x_k\\}\\]\n\r\\(X_k\\) follow t copula model\r\rJoshua C.C. Chan, Dirk P. Kroese. Efficient estimation of large portfolio loss probabilities in t-copula models. European Journal of Operational Research, 205:361–367, 2010.\n\r\\(X_k\\) follow another advanced models, e.g., self-exciting model, Giesecke et al. (2010)\r\rRandom default exposures: \\(c_k=e_k\\ell_k\\), where \\(\\ell_k\\in[0,1]\\) denotes a random\rpercentage loss, and \\(e_k\u0026gt;0\\) are constants.\r\\[L = \\sum_{k=1}^m e_k\\ell_k1\\{X_k\u0026gt;x_k\\}\\]\n\r\\(\\ell_k\\) are iid truncated normals or betas\r\r\rCross-entropy\rThe optimal proposal\rdensity is obtained by locating the member \\(p(x;\\theta),\\theta\\in\\Theta\\) that minimizes\rits cross-entropy distance to the zero-variance proposal\rdensity \\(q^*(x)\\propto h(x)p(x;\\theta_0)\\).\nThe minimization of the cross-entropy is equivalent to solving\rthe following maximization problem\r\\[\\max_{\\theta\\in\\Theta} \\int h(x)p(x;\\theta_0)\\log p(x;\\theta)d x=\\max_{\\theta\\in\\Theta} E_{\\theta_0}[h(X)\\log p(X;\\theta)]\\]\nSince most often an analytical solution to the above maximization\rproblem is not available, we consider instead its stochastic\rcounterpart\r\\[\\theta^*=\\arg \\max_{\\theta\\in\\Theta}\\frac 1{N_0}\\sum_{i=1}^{N_0}h(X_i)\\log p(X_i;\\theta),\\ X_i\\stackrel{iid}{\\sim} p(x;\\theta_0)\\]\nMore detials see Rubinstein (1997), Rubinstein \u0026amp; Kroese (2004).\n\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"5883ea17d6b0f16b6854de6822b32c40","permalink":"/zh/courses/bayes/chap10/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/chap10/","section":"courses","summary":"Introduction to Bayesian computation\rThe goals are to estimate\n\rthe posterior distribution \\(p(\\theta|y)\\propto p(\\theta)p(y|\\theta)\\)\n\rthe posterior predictive distribution\r\\[p(\\tilde y|y) = \\int p(\\tilde y|\\theta)p(\\theta|y)d \\theta =E[p(\\tilde y|\\theta)|y]\\]","tags":null,"title":"第10章","type":"docs"},{"authors":null,"categories":null,"content":"\rMarkov chains\rConsider the discrete chain:\r\\[P(X_i\\in A|X_0=x_0,\\dots,X_{i-1}=x_{i-1})=P(X_i\\in A|X_{i-1}=x_{i-1})\\]\n\r\\(X_i\\in\\Omega=\\{\\omega_1,\\dots,\\omega_M\\}\\)\n\rTransition distribution:\r\\[P(X_i=y|X_{i-1}=x)=T_i(y|x)\\]\n\rDistribution of this chain is now determined by \\(p_0(x)=P(X_0=x)\\) and \\(T_i(y|x)\\)\n\rHomogeneous chain:\r\\[P(X_i=y|X_{i-1}=x)=P(X_1=y|X_0=x)=T(y|x)\\]\n\r\r\rWhere does this chain go?\r\\[p_{i}(\\omega_k) = P(X_i=\\omega_k) = \\sum_{j=1}^Mp_{i-1}(\\omega_j)T(\\omega_k|\\omega_j)\\]\n\r\\(\\boldsymbol{p}_i=(p_i(\\omega_1),\\dots,p_i(\\omega_M))\\)\n\r\\(P\\) is the transition matrix with entries \\(P_{ij}=P(\\omega_j|\\omega_i)\\)\n\r\\(\\boldsymbol{p}_i = \\boldsymbol{p}_{i-1} P\\)\n\r\\(\\boldsymbol{p}_i = \\boldsymbol{p}_{0} P^n\\)\n\r\r\rExample: A portion of the Montréal métro\r\rTransition matrix\r\rAfter 100 steps\r\rNo matter where you start \\(p_{100}(\\text{Berri})\\doteq 0.31\\)\n\rThese are almost IID from the stationary distribution.\n\r\r\rStationary distribution\r\\[\\pi = \\pi P \\text{ so } \\pi^\\top = P^\\top\\pi^\\top\\]\n\r\\(\\pi^{\\top}\\) is an eigenvector of \\(P^\\top\\) with eigenvalue 1\r\r\rLaw of large numbers\rLet \\(X_i\\) be a time-homogenous Markov chain on a finite set \\(\\Omega\\)\nTheorem: If \\(P\\) is irreducible, then\n\\[P_{\\omega_0}\\left(\\lim_{n\\to\\infty}\\frac 1n\\sum_{i=1}f(X_i)=\\sum_{\\omega\\in\\Omega}\\pi(\\omega)f(\\omega)\\right)=1\\]\n\rIrreducibility: \\(P_x(\\tau_y\u0026lt;\\infty)\u0026gt;0\\) for any \\(x,y\\in \\Omega\\), where \\(\\tau_y\\) is the first time \\(y\\) is visited, i.e., \\[\\tau_y:=\\inf\\{i\\ge 1:X_i=y,X_0=x\\}\\]\r\r\rWhat we will do\r\rGiven \\(\\pi\\) we will find a transition matrix \\(P\\) with \\(\\pi P=\\pi\\)\n\rThen sample \\(X_1,\\dots,X_n\\) via \\(P\\)\n\r\rHere is what could go wrong:\n\rIt might take a long time before \\(\\boldsymbol{p}_n\\approx \\pi\\) (slow convergence)\n\r\\(X_n\\) might get stuck for a long time (slow mixing)\n\r\rThe goal is to find the good one for \\(P\\).\n\rDetailed balance\r\rStationarity balances flow into \\(y\\) with flow out of \\(y\\)\r\\[\\sum_{x\\in\\Omega} \\pi(x)P(y|x)=\\pi(y) = \\sum_{x\\in\\Omega}\\pi(y)P(x|y)\\]\rNB: \\(\\pi = \\pi P\\)\n\rDetailed balance is stronger:\r\\[\\pi(x)P(y|x)=\\pi(y)P(x|y),\\forall x,y\\in\\Omega\\]\n\rdetailed balance \\(\\rightarrow\\) balance\n\r\r\rThe road map\rThe goal is to build a Markov chain with a unique stationary distribution which equals the targe distribution.\nbuild a Markov chain with a unique stationary distribution. This holds if the Markov chian is irreducible, aperiodic, and not transient. E.g., random walk has a positive probablility of eventually reaching any state from any other state.\n\rstationary distribution = the targe distribution (detailed balance transition)\n\r\r\rThe Metropolis algorithm\rThe Metropolis algorithm (Metropolis et al. 1953) is an adaptation of a random walk with an acceptance/rejection rule to converge to the specified target distribution.\n\rtarget distribution: \\(p(x)\\)\n\rsymmetric proposal distribution at time \\(t\\): \\(q(y|x)=q(x|y)\\)\n\r\rThe algorithm goes below:\nfor \\(t=0\\), draw a starting poing \\(x_0\\sim p_0(x)\\)\rfor \\(t=1,2,\\dots\\), sample \\(y_t\\sim q(y_t|x_{t-1})\\), accept \\(y_t\\) as an output of \\(x_t\\) with probability\r\\[r(x_{t-1},y_t)=\\min\\left(\\frac{p(y_t)}{p(x_{t-1})},1\\right)\\]\rOtherwise, taking \\(x_{t}=x_{t-1}\\)\r\r\rThe transition for the Metropolis algorithm\rThe transition is a mixture of a point and a proposal distribution.\n\\[T(y|x) = r(x,y)q(y|x)+\\left[1-\\int r(x,y) q(y|x)dy\\right]1\\{y=x\\}\\]\n\\[r(x,y)=\\min\\left(\\frac{p(y)}{p(x)},1\\right)\\]\nDetailed balance: \\(p(x)T(y|x)=p(y)T(x|y)\\)\nIf \\(x\\neq y\\),\n\\[\\frac{p(x)T(y|x)}{p(y)T(x|y)}=\\frac{p(x)r(x,y)}{p(y)r(y,x)}\\frac{q(y|x)}{q(x|y)}=\\frac{p(x)\\min(p(y)/p(x),1)}{p(y)\\min(p(x)/p(y),1)}=1\\]\n\rRandom walk Metropolis\r\rthe proposal density:\r\r\\[y_{t+1}=x_t+ N(0,\\sigma^2I_d)\\]\n\\[y_{t+1}=x_t+ U[-\\sigma,\\sigma]^d\\]\nHow large a step \\(\\sigma\\)?\n\rTiny step: large \\(p(y_{t+1})/p(x_t)\\), high acceptance\n\rLarge step: small \\(p(y_{t+1})/p(x_t)\\), low acceptance\n\r\rWe might have wanted high acceptance and large moves. But there’s a tradeoff.\nThe rule of thumb: \\(\\sigma=2.38/\\sqrt{d}\\), see Gelman, Roberts, Gilks (1996)\n\rImprovements on RWM\r\rfor the target distribution \\(p\\approx N(\\mu,\\Sigma)\\)\n\rthe proposal: \\(y_{t+1}\\sim N(x_{t},\\lambda\\hat{\\Sigma})\\)\n\ruse sample \\(x_i\\) to estimate \\(\\Sigma\\)\n\ra tune parameter \\(\\lambda\\)\n\r\r\rExample: Bivariate unit normal with normal proposal\r\rtarget distribution: bivariate unit normal \\(N(0,I_2)\\)\n\rsymmetric proposal distribution: \\(q(y|x)=N(y|x,0.2^2I_2)\\)\n\r\r\rThe Metropolis-Hastings algorithm\rThe Metropolis-Hastings (MH) algorithm (Hastings, 1970) generalizes the basic Metropolis algorithm. The proposal needs no longer be symmetric.\nThe detailed balance:\n\\[p(x)r(x,y)q(y|x)=p(y)r(y,x)q(x|y)\\]\nHow to choose \\(r(x,y)\\) subject to \\(0\\le r(x,y)\\le 1\\)?\nThe result:\n\\[r(x,y)=\\min\\left(\\frac{p(y)q(x|y)}{p(x)q(y|x)},1\\right)\\]\n\rThe independent MH algorithm\r\rthe proposal: \\(q(y|x)=q(y)\\)\r\r\\[r(x,y)=\\min\\left(\\frac{p(y)q(x)}{p(x)q(y)},1\\right)\\]\n\rAlthough the proposal variates are iid, the states are not independent.\n\rWhat-if \\(q(x)=p(x)\\)?\n\r\r\rUnnormalized target density\rThe target density \\(p(x)=C\\tilde{p}(x)\\), where \\(C\u0026gt;0\\) is unknown constant.\n\\[\\frac{p(y)q(x|y)}{p(x)q(y|x)} = \\frac{C\\tilde{p}(y)q(x|y)}{C\\tilde{p}(x)q(y|x)}=\\frac{\\tilde{p}(y)q(x|y)}{\\tilde{p}(x)q(y|x)}\\]\nThe MH algorithm also works for unnormalized proposal density.\n\rEstimating the expectation\r\rThe law of large numbers supports:\r\\[\\hat\\mu = \\frac 1n\\sum_{i=1}^n f(X_i)\\]\n\rBurn-in (skipping the first \\(b\\) observations, e.g., \\(b=n/2\\))\r\\[\\hat\\mu_b = \\frac 1{n-b}\\sum_{i=b+1}^n f(X_i)\\]\n\rThinning (just use every \\(k\\)th observation, \\(k\u0026gt;1\\))\r\\[\\hat\\mu_k = \\frac 1{n/k}\\sum_{i=1}^{n/k} f(X_{ki})\\]\n\r\rSee Owen (2017)\n\rThe Gibbs sampler\rSuppose the targe distribution \\(X=(x_1,\\dots,x_d)\\sim p(X)\\). Maybe we can sample one \\(x_j\\) at a time, with others fixed, i.e., \\(x_j|x_{-j}\\), where \\(x_{-j}=(x_1,\\dots,x_{j-1},x_{j+1},\\dots,x_d)\\).\nRandom scan Gibbs: for \\(t=1,\\dots,n\\)\n\\(j\\sim U\\{1,\\dots,d\\}\\)\r\\(x_{-j}^{(t)}=x_{-j}^{(t-1)}\\)\r\\(x_{j}^{(t)}\\sim p(x_j|x_{-j}^{(t)})\\)\r\rDeterministic scan: \\(j\\) cycles through \\(1,\\dots,d\\) repeatedly, i.e., \\[j=1+(t-1) \\mod d\\]\n\rOne step of Gibbs\rIs a Metropolis-Hastings that always accepts, i.e., \\(r(x,y)\\equiv 1\\).\nProposal \\(q\\) just changes component \\(x_j\\): \\(p(x^{(t)}_j|x_{-j}^{(t-1)})\\)\nDetailed balance:\n\\[\\frac{p(y)q(x|y)}{p(x)q(y|x)}=\\frac{p(y_{-j})p(y_j|y_{-j})p(x_j|y_{-j})}{p(x_{-j})p(x_j|x_{-j})p(y_j|x_{-j})}=1\\]\nNB: \\(x_{-j}=y_{-j}\\)\n\rExample: Bivariate normal distribution\r\rtarget distribution: \\((x_1,x_2)^\\top\\sim N(\\mu,\\Sigma)\\)\n\r\\(\\mu=(\\mu_1,\\mu_2)^\\top,\\sigma_{11}=\\sigma_{22}=1,\\sigma_{12}=\\sigma_{21}=\\rho\\in (-1,1)\\)\n\rconditional distribution:\r\\[x_1|x_2\\sim N(\\mu_1+\\rho(x_2-\\mu_2),1-\\rho^2)\\]\n\r\r\\[x_2|x_1\\sim N(\\mu_2+\\rho(x_1-\\mu_1),1-\\rho^2)\\]\n\rThe simulation\r\rChanllenges of monitoring convergence: mixing and stationarity\r\rDid the chain mix well?\rWe can use the ACF or a trace.\nThe autocorrelation function (ACF) is a measure of the correlation between observations of a time series that are separated by \\(k\\) time units.\nRecent promising work by Gorham \u0026amp; Mackey using Stein discrepancy can\rprovide a “Yes” (but it’s expensive).\n\rExample: hierarchical normal model\rThe data \\(y_{ij},i=1,\\dots,n_j,j=1,\\dots,J\\):\nUnder the hierarchical normal model:\n\\[y_{ij}\\sim N(\\theta_j,\\sigma^2)\\]\n\\[\\theta_j\\sim N(\\mu,\\tau^2)\\]\nUniform prior distribution: \\((\\mu,\\log \\sigma,\\tau)\\propto 1\\)\r\\[(\\mu,\\log \\sigma,\\log \\tau)\\propto \\tau\\]\n\rPosterior distribution\rThe joint posterior density of all the parameters is\r\\[p(\\theta,\\mu,\\log \\sigma,\\tau|y) \\propto \\tau\\prod_{j=1}^J N(\\theta_j|\\mu,\\tau^2)\\prod_{j=1}^J\\prod_{i=1}^{n_j}N(y_{ij}|\\theta_j,\\sigma^2)\\]\n\rConditional posterior distribution\r\rfor \\(\\theta_j\\)\r\\[\\theta_j|\\mu,\\sigma,\\tau,y\\sim N(\\hat{\\theta}_j,V_{\\theta_j})\\]\n\rfor \\(\\mu\\)\r\\[\\mu|\\theta,\\sigma,\\tau,y\\sim N(\\hat{\\mu},\\tau^2/J),\\ \\hat{\\mu}=\\frac 1J\\sum_{j=1}^J\\theta_j\\]\n\rfor \\(\\sigma^2\\)\r\\[\\sigma^2|\\theta,\\mu,\\tau,y=\\sigma^2|\\theta,y\\sim \\mathrm{Inv-}\\chi^2(n,\\hat{\\sigma}^2)\\]\n\rfor \\(\\tau^2\\)\r\\[\\tau^2|\\theta,\\mu,\\sigma,y=\\tau^2|\\theta,\\mu,y\\sim \\mathrm{Inv-}\\chi^2(J-1,\\hat{\\tau}^2)\\]\n\r\r\\[\\hat{\\sigma}^2 = \\frac 1 n\\sum_{j=1}^J\\sum_{i=1}^{n_j}(y_{ij}-\\theta_j)^2,\\ \\hat{\\tau}^2=\\frac{1}{J-1}\\sum_{j=1}^J(\\theta_j-\\mu)^2\\]\n\rThe results\r\rStarting pionts: \\(\\theta_j^{(0)}\\sim U\\{y_{ij},i=1,\\dots,n_j\\},\\mu^{(0)}=\\frac 1 J\\sum_{j=1}^T \\theta_j^{(0)},(\\tau^2)^{(0)}\\sim \\mathrm{Inv-}\\chi^2(J-1,\\hat{\\tau}^2), (\\sigma^2)^{(0)}\\sim \\mathrm{Inv-}\\chi^2(n,\\hat{\\sigma}^2)\\)\n\rThe potential scale reduction \\(\\hat{R}\\), which declines to \\(1\\) as \\(n\\to\\infty\\)\n\r\r\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"7c528d1fe2a1b043374bda5d442a4d24","permalink":"/zh/courses/bayes/chap11/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/chap11/","section":"courses","summary":"Markov chains\rConsider the discrete chain:\r\\[P(X_i\\in A|X_0=x_0,\\dots,X_{i-1}=x_{i-1})=P(X_i\\in A|X_{i-1}=x_{i-1})\\]\n\r\\(X_i\\in\\Omega=\\{\\omega_1,\\dots,\\omega_M\\}\\)\n\rTransition distribution:\r\\[P(X_i=y|X_{i-1}=x)=T_i(y|x)\\]\n\rDistribution of this chain is now determined by \\(p_0(x)=P(X_0=x)\\) and \\(T_i(y|x)\\)\n\rHomogeneous chain:\r\\[P(X_i=y|X_{i-1}=x)=P(X_1=y|X_0=x)=T(y|x)\\]","tags":null,"title":"第11章","type":"docs"},{"authors":null,"categories":null,"content":"3 steps in BDA   set up the statistical model\n  compute the posterior distribution\n  model checking and model improvement\n  Statistical inference Goal: draw conclusions about unobserved quantities from the data (observed)\n  potentially observable quantities, e.g., future observations of a process\n  not directly observable quantities, e.g., unobservable population parameters\n  Notations and assumptions   unobservable population parameters of interest: $\\theta=(\\theta_1,\\dots,\\theta_m)$\n  the observed data: $y=(y_1,\\dots,y_n)$\n  potentially observable quantities: $\\tilde y$, e.g., $\\tilde y=y_{n+1}$\n  Assumption 1\n exchangeability: the $n$ values $y_i$ are exchangeable, e.g., iid samples conditonal on the population parameters.  Assumption 2\n conditional independence of $y$ and $\\tilde y$ given $\\theta$  Bayesian inference To make inferences about the posterior distributions, such as $p(\\theta|y)$ and $p(\\tilde y|y)$\nBayes\u0026rsquo; rule\n$$p(\\theta|y)=\\frac{p(\\theta,y)}{p(y)}=\\frac{p(y|\\theta)p(\\theta)}{p(y)}$$\n$$p(\\theta|y)\\propto p(y|\\theta)p(\\theta)$$\nThe imiplied constant is $$p(y)=\\int p(y|\\theta)p(\\theta) d \\theta.$$\nPrediction To make inferences about an unknown observable quantity\n  prior predictive distribution: $p(y)$\n  posterior predictive dsitribution: $p(\\tilde y|y)$\n  $$ p(\\tilde y|y) = \\int p(\\tilde y,\\theta|y)d\\theta = \\int p(\\tilde y|\\theta,y)p(\\theta|y)d \\theta = \\int p(\\tilde y|\\theta)p(\\theta|y)d \\theta $$\nAgain, $y$ and $\\tilde y$ are conditionally independent given $\\theta$.\nLikelihood $p(y|\\theta)$ is called the likelihood function, which is regarded as a function of $\\theta$.\nodds ratios\n$$\\frac{p(\\theta_1|y)}{p(\\theta_2|y)}=\\frac{p(\\theta_1)p(y|\\theta_1)/p(y)}{p(\\theta_2)p(y|\\theta_2)/p(y)}=\\frac{p(\\theta_1)}{p(\\theta_2)}\\frac{p(y|\\theta_1)}{p(y|\\theta_2)}$$\nposterior odds = prior odds $\\times$ likelihood ratio\nExample 1: inference about a genetic status  males: one X-chromosome + one Y-chromosome females: two X-chromosomes  Hemophilia is a disease that exhibits X-chromosome-linked recessive inheritance. The disease is generally fatal for women who inherit two such genes.\nConsider a woman who has an affected brother and her father is not affected. Let $\\theta$ be the state of the woman: a carrier of the gene ($\\theta=1$) or not ($\\theta=0$).\nPrior distribution: $P(\\theta=1)=P(\\theta=0)=0.5$\nData and model: She has two sons. Let $y_i=1$ or 0 denote the state of her sons. Now observe that her sons are not affected. Given $\\theta$, $y_1$ and $y_2$ are iid.\nExample 1: inference about a genetic status Likelihood function:\n$$P(y_1=0,y_2=0|\\theta=1)=0.5\\times 0.5=0.25$$\n$$P(y_1=0,y_2=0|\\theta=0)=1\\times 1=1$$\nPosterior distribution:\n$$P(\\theta=1|y) = \\frac{p(y|\\theta=1)p(\\theta=1)}{p(y)}=0.2$$\nExample 1: inference about a genetic status Adding more data: suppose that the woman has a third son, who is also unaffacted.\n$$P(\\theta=1|y_1,y_2,y_3) = \\frac{0.5\\times 0.2}{0.5\\times 0.2+1\\times 0.8}=0.111$$\nA key aspect of Bayesian analysis is the ease with which sequential analyses can be performed.\nQuestion: What happen if we suppose that the third son is affected?\nExample 2: spelling correction Classification of words is a problem of managing uncertainty. Suppose someone types radom. How should that be read?\n random radon radom  Data and model: Let $\\theta$ be the word that the person was intending to type, and let $y$ as the data. Now $y=$'radom\u0026rsquo; and $\\theta\\in${$\\theta_1$='random\u0026rsquo;,$\\theta_2$='radon\u0026rsquo;,$\\theta_3$='radom\u0026rsquo;}. The posterior density is\n$$P(\\theta|y=\\text{\u0026lsquo;radom\u0026rsquo;})\\propto p(\\theta)P(y=\\text{\u0026lsquo;radom\u0026rsquo;}|\\theta).$$\nExample 2: spelling correction Prior distribution: Here are probabilities supplied by researchers at Google. Goole Ngram Viewer: https://books.google.com/ngrams\n   $\\theta$ $p(\\theta)$     random $7.60\\times 10^{-5}$   radon $6.05\\times 10^{-6}$   radom $3.12\\times 10^{-7}$    Likelihood: Here are some conditional probabilities from Google\u0026rsquo;s model of spelling and typing errors:\n$\\theta$ | $p(\\text{\u0026lsquo;radom\u0026rsquo;}|\\theta)$ | -|-| random | $0.00193$ | radon | $0.000143$ | radom | $0.975$ |\nExample 2: spelling correction Posterior distribution:\n$\\theta$ | $p(\\theta)P(y=\\text{\u0026lsquo;radom\u0026rsquo;}|\\theta)$ | $P(\\theta|y=\\text{\u0026lsquo;radom\u0026rsquo;})$ | -|-|-| random | $1.47\\times 10^{-7}$ | 0.325 | radon | $8.65\\times 10^{-10}$ | 0.002 | radom | $3.04\\times 10^{-7}$ | 0.673 |\nModel improvement:\n including contextual info in the prior probabilities, e.g., statistical book. let $x$ be the contextual information used by the model.  $$p(\\theta|x,y)\\propto p(\\theta|x)p(y|\\theta,x)$$\n for simplicity, we may assume $p(y|\\theta,x)=p(y|\\theta)$.  ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"6bbe09d0aae49eeba7ad5f083e2ccbd0","permalink":"/zh/courses/bayes/chap2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/chap2/","section":"courses","summary":"3 steps in BDA   set up the statistical model\n  compute the posterior distribution\n  model checking and model improvement\n  Statistical inference Goal: draw conclusions about unobserved quantities from the data (observed)","tags":null,"title":"第2章","type":"docs"},{"authors":null,"categories":null,"content":"\rBinomial models\rEstimating a probability from binomial data\r\rlet \\(\\theta\\) be the proportion of successes in the population\n\rthe data \\((y_1,\\dots,y_n)\\in \\{0,1\\}^n\\)\n\rthe total number of successes in the \\(n\\) trials is denoted by \\(y\\)\n\rthe binomial model is\r\\[p(y|\\theta) = C_n^y\\theta^y(1-\\theta)^{n-y}\\]\n\rthe posterior distribution is\r\\[p(\\theta|y) \\propto p(\\theta)p(y|\\theta)\\propto p(\\theta)\\theta^y(1-\\theta)^{n-y}\\]\n\r\rExample: estimating the probability of a female birth\n\rA total of 241,945 girls and 251,527 boys were born in Paris from 1745 to 1770.\r\r\rHow to choose a proper prior?\r\rA naive choice for \\(p(\\theta)\\) is uniform on the interval \\([0,1]\\). Then\r\\[p(\\theta|y) \\propto \\theta^y(1-\\theta)^{n-y}\\]\n\rthat is, \\(\\theta|y\\sim Beta(y+1,n-y+1)\\)\n\r\r- \\(P(\\theta\\ge 0.5|y=241945,n=241945+251527)\\approx 1.15\\times 10^{-42}\\)\n\rPrediction\r\rLet \\(\\tilde y\\) be the result of a new trial\r\\[P(\\tilde y =1|y) = \\int_0^1 P(\\tilde y=1|\\theta,y)p(\\theta|y)d \\theta=E[\\theta|y]=\\frac{y+1}{n+2}\\]\r\rPosterior as compromise between data and prior information\n\rprior mean is \\(1/2\\)\rsample mean is \\(y/n\\)\rposterior mean is \\((y+1)/(n+2)\\)\rthe compromise is controlled to a greater extent by the data as the sample size\rincreases.\r\r\rPosterior quantiles and intervals\r\rlet \\(T_1\\) be the \\(\\alpha/2\\) quantile of the posterior distribution\rlet \\(T_2\\) be the \\(1-\\alpha/2\\) quantile of the posterior distribution\r\\(100(1-\\alpha)\\%\\) posterior interval is \\([T_1,T_2]\\)\r\r\rcompare with the usual confidence interval\r\r\rInformative prior distributions\rGoal: assigning a prior distribution that reflects substantive info.\n\rthe likelihood is\r\\[p(y|\\theta) \\propto \\theta^y(1-\\theta)^{n-y}\\]\n\rchoose a prior as a \\(Beta(\\alpha,\\beta)\\) distribution:\r\\[p(\\theta) \\propto \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\\]\n\rthe parameters \\(\\alpha,\\beta\u0026gt;0\\) of the prior distribution is called hyperparameters.\n\rthe posterior is\r\\[p(\\theta|y)\\propto \\theta^{\\alpha+y-1}(1-\\theta)^{n-y+\\beta-1}=Beta(\\alpha+y,\\beta+n-y)\\]\n\r\r\rInformative prior distributions\r\rthe posterior mean is\r\\[E[\\theta|y]=\\frac{\\alpha+y}{\\alpha+\\beta+n}\\]\rwhich lies between the sample proportion \\(y/n\\) and the prior mean \\(\\alpha/(\\alpha+\\beta)\\)\n\rthe posterior variance is\r\\[Var[\\theta|y]=\\frac{(\\alpha+y)(\\beta+n-y)}{(\\alpha+\\beta+n)^2(\\alpha+\\beta+n+1)}=\\frac{E[\\theta|y](1-E[\\theta|y])}{\\alpha+\\beta+n+1}\\]\n\ras \\(y\\) and \\(n\\) become large with fixed \\(\\alpha,\\beta\\),\r\\[E[\\theta|y]\\approx \\frac yn,\\ Var[\\theta|y]\\approx \\frac 1n\\frac yn(1-\\frac yn).\\]\n\r\r\rConjugate prior distributions\rDefinition: If \\(\\mathcal{F}\\) is a class of sampling distribution \\(p(y|\\theta)\\), and \\(\\mathcal{P}\\) is a class of prior distributions for \\(\\theta\\), then the class \\(\\mathcal{P}\\) is conjugate for \\(\\mathcal{F}\\) if\r\\[p(\\theta|y)\\in \\mathcal{P} \\text{ for all } p(\\cdot|\\theta)\\in\\mathcal{F} \\text{ and }p(\\cdot)\\in\\mathcal{P}.\\]\nAdvantages of conjugate prior distributions\n\rcomputational convenience\rcan be interpreted as additional data\r\r\rExponential families\rDefinition: The class \\(\\mathcal{F}\\) is an exponential family if all its members have the form\r\\[p(y_i|\\theta)=f(y_i)g(\\theta)\\exp[\\phi(\\theta)^\\top u(y_i)].\\]\n\r\\(f(\\cdot)\\ge 0\\)\r\\(\\phi(\\theta)\\) is called the natural parameter\r\rFor iid samples, we have\r\\[p(y|\\theta)=\\left(\\prod_{i=1}^n f(y_i)\\right)g(\\theta)^n\\exp\\left[\\phi(\\theta)^\\top \\sum_{i=1}^nu(y_i)\\right]\r\\]\r\\[p(y|\\theta)\\propto g(\\theta)^n\\exp[\\phi(\\theta)^\\top t(y)]\\]\n\rwhere \\(t(y)=\\sum_{i=1}^nu(y_i)\\) (i.e., a sufficient statistic for \\(\\theta\\)).\r\r\rConjugate prior distribution for exponential families\rIf the prior distribution is specified as\r\\[p(\\theta)\\propto g(\\theta)^\\eta \\exp[\\phi(\\theta)^\\top \\nu],\\]\rthen the posterior density is\r\\[p(\\theta|y)\\propto g(\\theta)^{\\eta+n} \\exp[\\phi(\\theta)^\\top (\\nu+t(y))].\\]\nA list of exponential families\n\rbinomial distributions\rnormal distributions\rexponential distributions\rpossion distributions\r\r\rExample: Probability of a girl birth given placenta previa\rAn early study concerning the sex of placenta previa births in Germany found that of a total of 980 births, 437 were female.\nHow much evidence does this provide for the claim that the proportion of female births in the population of placenta previa births is less than 0.485, the proportion of female births in the general population?\n\rusing a uniform prior: the posterior is \\(Beta(438,544)\\). The central \\(95\\%\\) posterior interval is \\([0.415,0.477]\\).\n\rusing conjugate prior \\(Beta(\\alpha,\\beta)\\)\n\rusing nonconjugate prior\n\r\r\rDifferent conjugate prior distributions\r\r\r\\(\\alpha/(\\alpha+\\beta)\\)\r\\(\\alpha+\\beta\\)\rposterior median\r\\(95\\%\\) posterior interval\r\r\r\r0.500\r2\r0.446\r[0.415, 0.477]\r\r0.485\r2\r0.446\r[0.415, 0.477]\r\r0.485\r5\r0.446\r[0.415, 0.477]\r\r0.485\r10\r0.446\r[0.415, 0.477]\r\r0.485\r20\r0.447\r[0.416, 0.478]\r\r0.485\r100\r0.450\r[0.420, 0.479]\r\r0.485\r200\r0.453\r[0.424, 0.481]\r\r\r\r\rPosterior inferences based on a large sample are not sensitive to the prior distribution.\rAll the \\(95\\%\\) posterior intervals exclude the prior mean.\r\r\rThe effect of prior distributions\r\rUsing a nonconjugate prior distribution\r\\(95\\%\\) posterior interval is [0.419, 0.480]\n\r\rNormal models\rEstimating a normal mean with known variance\rLikelihood function:\r\\[p(y|\\theta) = \\prod_{i=1}^n \\frac 1{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i-\\theta)^2}{2\\sigma^2}}\\propto e^{-\\frac{n\\theta^2}{2\\sigma^2}}e^{\\frac{n\\theta\\bar y}{\\sigma^2}}\\]\nConjugate prior: \\(\\theta\\sim N(\\mu_0,\\tau_0^2)\\)\nPosterior distribution:\r\\[p(\\theta|y)\\propto e^{-\\frac{n\\theta^2}{2\\sigma^2}}e^{\\frac{n\\theta\\bar y}{\\sigma^2}}e^{-\\frac{\\theta^2}{2\\tau_0^2}}e^{\\frac{\\mu_0\\theta}{\\tau_0^2}}=N(\\mu_n,\\tau_n^2)\\]\nwhere\r\\[\\mu_n=\\frac{\\frac 1{\\tau_0^2}\\mu_0+\\frac n{\\sigma^2}\\bar y}{\\frac 1{\\tau_0^2}+\\frac n{\\sigma^2}},\\ \\frac1{\\tau_n^2}=\\frac{1}{\\tau_0^2}+\\frac n{\\sigma^2}.\\]\n\rComments\r\rthe inverse of the variance plays a prominet role and is called the precision\rposterior precision = prior precision + data precision\rthe posterior mean is expressed as a weighted average of the prior mean \\(\\mu_0\\) and the sample mean \\(\\bar y\\), with weights proportional to the precisions.\rwhat happens if \\(n\\to \\infty\\) with \\(\\tau_0^2\\) fixed? data info. dominated!\rwhat happens if \\(\\tau_0\\to \\infty\\) with \\(n\\) fixed? This would result from assuming \\(p(\\theta)\\) is proportional to a constant for \\(\\theta\\in(-\\infty,\\infty)\\). (improper prior, serves as an noninformative prior)\r\r\rNormal distribution with known mean but unknown variance\rLikelihood function:\r\\[p(y|\\sigma^2)=\\prod_{i=1}^n \\frac 1{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i-\\mu)^2}{2\\sigma^2}}\\propto \\sigma^{-n}\\exp\\left[-\\frac{n}{2\\sigma^2}\\nu\\right]\\]\rwhere the sufficient statistic is\r\\[\\nu=\\frac 1n\\sum_{i=1}^n(y_i-\\mu)^2.\\]\rConjugate prior density:\r\\[p(\\sigma^2)\\propto (\\sigma^2)^{-(\\alpha+1)}e^{-\\beta/\\sigma^2},\\]\rwhere the hyperparameters is \\((\\alpha,\\beta)\\).\nWe may take \\(\\sigma^2\\sim \\text{Inv-}\\chi^2(\\nu_0,\\sigma^2_0)\\) as a prior (i.e., \\(\\sigma^2\\stackrel d {=}\\sigma_0^2\\nu_0/\\chi^2_{\\nu_0}\\)), whose PDF is given by\r\\[p(\\sigma^2) =\\frac{(\\nu_0/2)^{\\nu_0/2}}{\\Gamma(\\nu_0/2)}\\sigma^{\\nu_0}_0(\\sigma^2)^{-(\\nu_0/2+1)}e^{-\\nu_0\\sigma_0^2/(2\\sigma^2)}.\\]\n\rNormal distribution with known mean but unknown variance\rPrior density:\r\\[p(\\sigma^2)= \\text{Inv-}\\chi^2(\\nu_0,\\sigma^2_0)\\]\nPosterior density:\r\\[p(\\sigma^2|y)=\\text{Inv-}\\chi^2\\left(\\nu_0+n,\\frac{\\nu_0\\sigma_0^2+n\\nu}{\\nu_0+n}\\right)\\]\n\rdegree of freedom = sum of the prior and data\n\rscale = weighted average of the prior and data\n\rif \\(\\nu_0=0\\), \\(p(\\sigma^2|y)=\\text{Inv-}\\chi^2(n,\\nu)\\), as effectively taking \\(p(\\sigma^2)\\propto 1/\\sigma^2\\) (improper prior, serves as an noninformative prior)\n\r\r\r\rPoisson models\rPoisson models\rApplications: The Possion distribution arises naturally in the study of data taking the form of counts.\n\rnumber of customer on the queue over an unit time\repidemiology – the incidence of diseases\r\rLikelihood function:\r\\[p(y|\\theta) = \\prod_{i=1}^n\\frac{\\theta^{y_i}e^{-\\theta}}{y_i!}\\propto \\theta^{t(y)}e^{-n\\theta}\\propto e^{-n\\theta}e^{t(y)\\log \\theta}\\]\n\r\\(t(y)=\\sum_{i=1}^n y_i\\) is the sufficient statistic\rthe natural parameter is \\(\\log \\theta\\)\r\rConjugate prior:\r\\[p(\\theta)\\propto e^{-\\eta\\theta}e^{\\nu\\log \\theta}\\]\nSo we may choose \\(p(\\theta)=Gamma(\\alpha,\\beta)\\propto \\theta^{\\alpha-1}e^{-\\beta\\theta}\\)\n\rPoisson models\rPrior density: \\(p(\\theta)=Gamma(\\alpha,\\beta)\\)\nPosterior density: \\(p(\\theta|y)=Gamma(\\alpha+n\\bar y,\\beta+n)\\)\nMarginal density:\r\\[p(y_i)=C_{\\alpha+y_i-1}^{y_i} \\left(\\frac{\\beta}{\\beta+1}\\right)^\\alpha\\left(\\frac{1}{\\beta+1}\\right)^{y_i}\\]\n\r\\(y_i\\sim \\text{Neg-bin}(\\alpha,\\beta)\\), i.e., the negative binomial distribution\r\r\rPossion models: an extension\rIn many applications, it is convenient to extend the Possion model for data pionts \\(y_1,\\dots,y_n\\) to the form\r\\[y_i\\sim Poission(x_i\\theta),\\]\n\rthe values \\(x_i\\) are known positive values of an explanatory variable \\(x\\), called the exposure of the \\(i\\)th unit\n\r\\(\\theta\\) is unknown, called the rate\n\r\rPrior density: \\(p(\\theta)=Gamma(\\alpha,\\beta)\\)\nPosterior density:\r\\[p(\\theta|y)=Gamma(\\alpha+\\sum_{i=1}^ny_i,\\beta+\\sum_{i=1}^nx_i)\\]\nExample: Bayesian inference for the cancer death rates (p.48)\n\r\rExponential models\rExponential models\rApplications: The expoential distribution is commonly used to model ‘waiting times’ and other continuous, poisitive, real-valued random variables. It has a ‘memoryless’ property that makes it a natural model for survival or lifetime data.\nLikelihood function:\r\\[p(y|\\theta) = \\prod_{i=1}^n\\theta \\exp(-y_i\\theta)= \\theta^{n}e^{-n\\bar y \\theta}\\]\nPrior density: \\(p(\\theta)=Gamma(\\alpha,\\beta)\\)\nPosterior density:\r\\[p(\\theta|y)=Gamma(\\alpha+n,\\beta+n\\bar y)\\]\n\rSummary\r\r\rPopulation\rParameter\rConjugate prior\r\r\r\rBinomial\rprobability of success\rBeta dist.\r\rPossion\rmean\rGamma dist.\r\rExponential\rinverse mean\rGamma dist.\r\rNormal (known variance)\rmean\rNormal dist.\r\rNormal (known mean)\rvariance\rInv-Gamma dist.\r\r\r\r\rEnd notes\r\rtwo kinds of prior distributions: uniform (noninformative) and conjugate (informative)\n\rsome other noninformative prior distributions: Jeffreys’ prior etc. See pp.52-56\n\rnoninformative prior are often useful when it does not seem to be worth the effort to quantify one’s real prior knowledge as a probability distribution\n\rwhen using conjugate prior, it remains to choose the hyperparameters; see Chapter 5 for hierarchical models\n\r\r\r\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"86d5e5d011a52ada9195db5ad4718d9c","permalink":"/zh/courses/bayes/chap3/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/chap3/","section":"courses","summary":"Binomial models\rEstimating a probability from binomial data\r\rlet \\(\\theta\\) be the proportion of successes in the population\n\rthe data \\((y_1,\\dots,y_n)\\in \\{0,1\\}^n\\)\n\rthe total number of successes in the \\(n\\) trials is denoted by \\(y\\)","tags":null,"title":"第3章","type":"docs"},{"authors":null,"categories":null,"content":"\rNuisance parameters\r\rthere are more than one unknown or unobservable parameters\n\rconclusions will often be drawn about one, or only a few parameters at a time\n\rthere is no interest in making inferences about many of the unknown parameters – nuisance parameters\n\rsuppose \\(\\theta=(\\theta_1,\\theta_2)\\)\n\rinterest centers only on \\(\\theta_1\\); \\(\\theta_2\\) is a ‘nuisance’ parameter.\n\rthe joint posterior density:\r\\[p(\\theta_1,\\theta_2|y)\\propto p(y|\\theta_1,\\theta_2)p(\\theta_1,\\theta_2)\\]\n\rthe marginal posterior density:\r\\[p(\\theta_1|y)=\\int p(\\theta_1,\\theta_2|y)d\\theta_2=\\int p(\\theta_1|\\theta_2,y)p(\\theta_2|y)d\\theta_2\\]\n\r\r\rNormal data with a noninformative prior distribution\rLikelihood function:\r\\[p(y|\\mu,\\sigma^2)=\\prod_{i=1}^n \\frac 1{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y_i-\\theta)^2}{2\\sigma^2}}\\]\nNoninformative prior distribution:\r\\[p(\\mu,\\sigma^2)\\propto 1\\times (\\sigma^2)^{-1}\\]\nPosterior distribution:\r\\[p(\\mu,\\sigma^2|y)\\propto \\sigma^{-n-2}e^{-\\frac{\\sum_{i=1}^n(y_i-\\theta)^2}{2\\sigma^2}}=\\sigma^{-n-2}e^{-\\frac{(n-1)s^2+n(\\bar y-\\mu)^2}{2\\sigma^2}}\\]\n\r\\(s^2=\\frac 1{n-1}\\sum_{i=1}^n(y_i-\\bar y)^2\\) is the sample variance\r\r\rNormal data with a noninformative prior distribution\rConditional posterior distribution:\r\\[p(\\mu|\\sigma^2,y)\\sim N(\\bar y,\\sigma^2/n)\\]\nMarginal posterior distribution \\(p(\\sigma^2|y)\\):\r\\[p(\\sigma^2|y)\\propto \\int \\sigma^{-n-2}e^{-\\frac{(n-1)s^2+n(\\bar y-\\mu)^2}{2\\sigma^2}} d\\mu=(\\sigma^2)^{-\\frac{n+1}2}e^{-\\frac{(n-1)s^2}{2\\sigma^2}}\\]\n\\[\\sigma^2|y\\sim \\text{Inv-}\\chi^2(n-1,s^2)\\]\n\rNormal data with a noninformative prior distribution\rMarginal posterior distribution \\(p(\\mu|y)\\):\n\\[p(\\mu|y)\\propto \\int_0^\\infty \\sigma^{-n-2}e^{-\\frac{(n-1)s^2+n(\\bar y-\\mu)^2}{2\\sigma^2}} d\\sigma^2\\propto \\left[1+\\frac{n(\\mu-\\bar y)^2}{(n-1)s^2}\\right]^{-\\frac n2}\\]\n\\[\\mu|y\\sim t_{n-1}(\\bar y,s^2/n),\\ \\frac{\\mu-\\bar y}{s/\\sqrt{n}}\\Big|y\\sim t_{n-1}\\]\nPosterior predictive distribution for a future observation\n\\[\\tilde y|y \\sim t_{n-1}(\\bar y,(1+1/n)s^2)\\]\n\rExample: Estimating the speed of light\rSimon Newcomb set up an experiment in 1882 to measure the speed of light. Newcom measured the amount of time rquired for light to travel a distance of 7442 meters (66 measurements, from Stigler (1977), the data are recorded as deviations from 24800 nanoseconds).\n\r\\(n=66,\\ \\bar y = 26.2,\\ s = 10.8\\)\r\\((\\mu-26.2)/(10.8/\\sqrt{66})|y\\sim t_{65}\\)\r\\(95\\%\\) central posterior interval for \\(\\mu\\) is \\(26.2\\pm 10.8t_{65,0.975}/\\sqrt{66}=[23.6,28.8]\\)\rthe speed of light is 299792458 m/s, so the true value for \\(\\mu\\) is \\(23.8\\) nanoseconds\r\r\rExample: Estimating the speed of light\r\rNormal data with a conjugate prior distribution\rPrior distribution:\r\\[\\mu|\\sigma^2\\sim N(\\mu_0,\\sigma^2/\\kappa_0),\\]\n\\[\\sigma^2\\sim \\text{Inv-}\\chi^2(\\nu_0,\\sigma_0^2).\\]\n\\[p(\\mu,\\sigma^2)\\propto \\sigma^{-1}(\\sigma^2)^{-(\\nu_0/2+1)}\\exp\\left(-\\frac 1{2\\sigma^2}[\\nu_0\\sigma^2+\\kappa_0(\\mu_0-\\mu)^2]\\right)\\]\n\rdenoted by \\(\\text{N-Inv-}\\chi^2(\\mu_0,\\sigma^2_0/\\kappa_0;\\nu_0,\\sigma_0^2)\\)\r\r\rNormal data with a conjugate prior distribution\rPosterior distribution:\n\\[\\mu,\\sigma^2|y\\sim \\text{N-Inv-}\\chi^2(\\mu_n,\\sigma^2_n/\\kappa_n;\\nu_n,\\sigma_n^2)\\]\n\\[\r\\begin{cases}\r\\mu_n \u0026amp;= \\frac{\\kappa_0}{\\kappa_0+n}\\mu_0+\\frac{n}{\\kappa_0+n}\\bar y\\\\\r\\kappa_n \u0026amp;= \\kappa_0+n\\\\\r\\nu_n\u0026amp;=\\nu_0+n\\\\\r\\nu_n\\sigma_n^2 \u0026amp;= \\nu_0\\sigma_0^2+(n-1)s^2+\\frac{\\kappa_0n}{\\kappa_0+n}(\\bar y-\\mu_0)^2\r\\end{cases}\r\\]\n\r\\(\\mu|\\sigma^2,y\\sim N(\\mu_n,\\sigma^2/\\kappa_n)\\)\r\\(\\sigma^2|y\\sim \\text{Inv-}\\chi^2(\\nu_n,\\sigma_n^2)\\)\r\\(\\mu|y\\sim t_{\\nu_n}(\\mu_n,\\sigma_n^2/\\kappa_n)\\)\r\r\rMultinormal model for categorical data\rThe multinomial sampling distribution is used to describe data for which each observation is one of \\(k\\) possible outcomes. If \\(y\\) is the vector of counts of the number of observations of each outcome, then\r\\[p(y|\\theta)\\propto \\prod_{j=1}^k\\theta_j^{y_j},\\]\rwhere \\(\\sum_{j=1}^k\\theta_j=1\\).\nConjugate prior:\r\\[p(\\theta|\\alpha)\\propto \\prod_{j=1}^k\\theta_j^{\\alpha_j-1}\\]\n\rDirichlet distribution\r\rPosterior distribution:\r\\[p(\\theta|y)\\propto \\prod_{j=1}^k\\theta_j^{y_j+\\alpha_j-1}\\]\n\rMultivariate normal model with known variance\rLikelihood function:\r\\[p(y_1,\\dots,y_n|\\mu,\\Sigma)\\propto |\\Sigma|^{-n/2}\\exp\\left(-\\frac 12\\sum_{i=1}^n(y_i-\\mu)^\\top\\Sigma^{-1}(y_i-\\mu)\\right)\\]\nConjuate prior: \\(\\mu\\sim N(\\mu_0,\\Lambda_0)\\)\nPosterior distribution: \\(\\mu|y\\sim N(\\mu_n,\\Lambda_n)\\)\n\r\\(\\mu_n=(\\Lambda_n^{-1}+n\\Sigma^{-1})^{-1}(\\Lambda_0^{-1}\\mu_0+n\\Sigma^{-1}\\bar y)\\)\r\\(\\Lambda_n^{-1} = \\Lambda_n^{-1}+n\\Sigma^{-1}\\)\r\r\rMultivariate normal model with unknown mean and variance\rPrior distribution: the normal-inverse-Wishart \\((\\mu_0,\\kappa_0;\\nu_0,\\Lambda_0)\\)\n\\[\\Sigma\\sim \\text{Inv-Wishart}_{\\nu_0}(\\Lambda_0^{-1})\\]\r\\[\\mu|\\Sigma\\sim N(\\mu_0,\\Sigma/\\kappa_0)\\]\r\\[p(\\mu,\\Sigma)\\propto |\\Sigma|^{-\\frac{\\nu_0+d}{2}-1}\\exp\\left(-\\frac{1}{2}tr(\\Lambda_0\\Sigma^{-1})-\\frac {\\kappa_0}2(\\mu-\\mu_0)^\\top\\Sigma^{-1}(\\mu-\\mu_0)\\right)\\]\nPosterior distribution: the normal-inverse-Wishart \\((\\mu_n,\\kappa_n;\\nu_0,\\Lambda_n)\\)\n\\[\r\\begin{cases}\r\\mu_n \u0026amp;= \\frac{\\kappa_0}{\\kappa_0+n}\\mu_0+\\frac{n}{\\kappa_0+n}\\bar y\\\\\r\\kappa_n \u0026amp;= \\kappa_0+n\\\\\r\\nu_n\u0026amp;=\\nu_0+n\\\\\r\\Lambda_n \u0026amp;= \\Lambda_0+\\sum_{i=1}^n(y_i-\\bar y)(y_i-\\bar y)^\\top+\\frac{\\kappa_0n}{\\kappa_0+n}(\\bar y-\\mu_0)(\\bar y-\\mu_0)^\\top\r\\end{cases}\r\\]\n\rMultivariate normal model with unknown mean and variance\r\r\\(\\Sigma|y\\sim \\text{Inv-Wishart}_{\\nu_n}(\\Lambda_n^{-1}),\\ \\mu|\\Sigma,y\\sim N(\\mu_n,\\Sigma/\\kappa_n)\\)\n\r\\(\\mu|y \\sim t_{\\nu_n-d+1}(\\mu_,\\Lambda_n/(\\kappa_n(\\nu_n-d+1)))\\) multivariate t distriution.\n\r\\(\\tilde y|y \\sim t_{\\nu_n-d+1}(\\mu_,(k_n+1)\\Lambda_n/(\\kappa_n(\\nu_n-d+1)))\\)\n\r\r\rWishart distributions\rLet \\(X_i \\stackrel {iid}\\sim N_p(0, \\Sigma)\\), where \\(\\Sigma\\) is \\(p\\times p\\) definite matrix, and \\(i=1,\\dots,n\\).\n\\[W=\\sum_{i=1}^n X_iX_i\u0026#39;\\in R^{p\\times p}\\]\nis called the Wishart distribution with \\(n\\) degree of freedom, denoted by \\(\\text{Wishart}_n(\\Sigma)\\).\n\rif \\(p=\\Sigma = 1\\), then it is a chi-squared distribution with \\(n\\) degrees of freedom.\n\rFor \\(n \\ge p\\) the matrix \\(W\\) is invertible with probability 1.\n\rif \\(X_i \\stackrel {iid}\\sim N_p(\\mu, \\Sigma)\\), then\n\r\r\\[(n-1)S^2 = \\sum_{i=1}^n (X_i-\\bar X)(X_i-\\bar X)\u0026#39;\\sim \\text{Wishart}_{n-1}(\\Sigma).\\]\n\rInverse-Wishart distributions\rIf \\(W\\sim \\text{Wishart}_n(\\Sigma)\\) with \\(n\\ge p\\), then \\(W^{-1}\\sim \\text{Inv-Wishart}_n(\\Sigma^{-1})\\).\n\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"ef4274820c9b9ca5d3e38a963234c506","permalink":"/zh/courses/bayes/chap4/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/chap4/","section":"courses","summary":"Nuisance parameters\r\rthere are more than one unknown or unobservable parameters\n\rconclusions will often be drawn about one, or only a few parameters at a time\n\rthere is no interest in making inferences about many of the unknown parameters – nuisance parameters","tags":null,"title":"第4章","type":"docs"},{"authors":null,"categories":null,"content":"\rLarge-sample theory\rAssumptions and notations:\n\rtrue distribution: \\(y_i\\stackrel {iid}{\\sim} f(\\cdot)\\)\n\r\\(\\theta\\in\\Theta\\)\n\rprior distribution: \\(p(\\theta)\\)\n\rmodel distribution: \\(p(y|\\theta)\\)\n\rKullback-Leibler divergence: a measure of ‘discrepancy’ between the model and the true distribution\r\\[KL(\\theta)= E_f\\left[\\log\\left(\\frac{f(y)}{p(y|\\theta)}\\right)\\right]=\\int \\log\\left(\\frac{f(y)}{p(y|\\theta)}\\right)f(y)dy\\]\n\r\\(\\theta_0\\): the unique minimizer of \\(KL(\\theta)\\)\n\rif \\(f(y) = p(y|\\theta)\\) then \\(\\theta=\\theta_0\\)\n\r\r\rConsistency of the posterior distribution\rDiscrete parmeter space: If the parameter space \\(\\Theta\\) is finite and \\(P(\\theta=\\theta_0)\u0026gt;0\\), then\r\\[P(\\theta=\\theta_0|y)\\to 1\\text{ as }n\\to \\infty,\\]\rwhere \\(\\theta_0=\\arg_{\\theta\\in\\Theta} KL(\\theta)\\).\nContinuous parmeter space: If \\(\\theta\\) is defined on a compace set \\(\\Theta\\) and \\(A\\) is a neighborhood of \\(\\theta_0\\) with \\(P(\\theta\\in A)\u0026gt;0\\), then\r\\[P(\\theta\\in A|y)\\to 1\\text{ as }n\\to \\infty,\\]\rwhere \\(\\theta_0=\\arg_{\\theta\\in\\Theta} KL(\\theta)\\).\nSee the proofs in Appendix B.\n\rNormal approximations to the posterior distribution\r\r\\(\\hat \\theta\\): the posterior mode\n\rTaylor series expansion of \\(\\log p(\\theta|y)\\) gives\r\\[\\log p(\\theta|y) = \\log p(\\hat \\theta|y)-\\frac 12 (\\theta-\\hat\\theta)^\\top I(\\hat \\theta) (\\theta-\\hat\\theta) + \\cdots \\]\n\rwhere \\(I(\\theta)\\) is the observed information\r\\[I(\\theta)=-\\frac{d^2}{d\\theta^2}\\log p(\\theta|y)\\]\n\rNormal approximation: \\(p(\\theta|y)\\approx N(\\hat\\theta,[I(\\hat\\theta)]^{-1})\\)\n\rFisher information:\r\\[J(\\theta)=-E_f\\left[\\frac{d^2}{d\\theta^2}\\log p(y_j|\\theta)\\right]\\]\n\r\r\rConvergence of the posterior distribution to normality\rTheorem: Under some regularity conditions (notably that \\(\\theta\\) not be on the boundary of \\(\\Theta\\)), as \\(n\\to \\infty\\), the posterior distribution of \\(\\theta\\) approaches normality with mean \\(\\theta_0\\) and variance \\([nJ(\\theta_0)]^{-1}\\), where \\(\\theta_0=\\arg_{\\theta\\in\\Theta} KL(\\theta)\\) and \\(J\\) is the Fisher information.\nOberved that:\n\r\\(\\hat\\theta\\to \\theta_0\\) as \\(n\\to \\infty\\)\n\r\\(I(\\hat\\theta)=-\\frac{d^2}{d\\theta^2}\\log p(\\hat\\theta)-\\sum_{i=1}^n\\frac{d^2}{d\\theta^2}\\log p(y_i|\\hat\\theta)\\approx nJ(\\theta_0)\\)\n\r\\(nJ(\\theta_0)=\\frac{d^2}{d\\theta^2} KL(\\theta_0)\u0026gt;0\\)\n\r\rNB: \\(\\frac{d^2}{d\\theta^2} KL(\\theta)= \\frac{d^2}{d\\theta^2} E_f\\left[-\\log p(y|\\theta) \\right]=-n\\frac{d^2}{d\\theta^2} E_f\\left[\\log p(y_i|\\theta) \\right]=-n E_f\\left[\\frac{d^2}{d\\theta^2}\\log p(y_i|\\theta) \\right]\\) if the interchange of expectation and derivative is allowed.\n\rCounterexamples to the theorems\r\runderidentified models: \\(p(y|\\theta)\\) is equal for a range of values of \\(\\theta\\)\n\rnonindentified parameters: for example, consider the model,\r\\[\\left(\r\\begin{matrix}\ru\\\\\rv\r\\end{matrix}\r\\right)\\sim N \\left( \\left(\\begin{matrix}\r0\\\\\r0\r\\end{matrix}\r\\right),\\left(\\begin{matrix}\r1\u0026amp;\\rho\\\\\r\\rho \u0026amp; 1\r\\end{matrix}\r\\right)\\right)\\]\ronly one of \\(u,v\\) is observed from each pair \\((u,v)\\)\n\rnumber of parameters increasing with sample sizes: new latent parameters with each data point\n\r\r\rPoint estimation, consistency, and efficiency\rpoint estimations:\n\rposterior mode \\(\\hat\\theta(y)=\\arg \\max_{\\theta\\in\\Theta} p(\\theta|y)\\)\rposterior mean \\(\\hat\\theta(y)=E[\\theta|y]=\\int \\theta p(\\theta|y)d \\theta\\) (the optimal one under the Bayesian decision rule)\rposterior median \\(\\hat\\theta(y)=F^{-1}_{\\theta|y}(0.5)\\)\r\rconsistency: \\(\\hat\\theta(y)\\to \\theta_0\\) as \\(n\\to \\infty\\)\nasymptotic unbiasedness: \\(E[\\hat\\theta|\\theta_0]\\to\\theta_0\\) as \\(n\\to \\infty\\)\nefficiency:\r\\[\\text{eff}(\\hat\\theta)=\\frac{\\inf_T E[(T(y)-\\theta_0)^2|\\theta_0]}{E[(\\hat\\theta-\\theta_0)^2|\\theta_0]}\\le 1\\]\nasymptotically efficient: \\(\\text{eff}(\\hat\\theta)\\to 1\\) as \\(n\\to \\infty\\)\n\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"815fb36171c91a59db806202e9d24501","permalink":"/zh/courses/bayes/chap5/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/chap5/","section":"courses","summary":"Large-sample theory\rAssumptions and notations:\n\rtrue distribution: \\(y_i\\stackrel {iid}{\\sim} f(\\cdot)\\)\n\r\\(\\theta\\in\\Theta\\)\n\rprior distribution: \\(p(\\theta)\\)\n\rmodel distribution: \\(p(y|\\theta)\\)\n\rKullback-Leibler divergence: a measure of ‘discrepancy’ between the model and the true distribution\r\\[KL(\\theta)= E_f\\left[\\log\\left(\\frac{f(y)}{p(y|\\theta)}\\right)\\right]=\\int \\log\\left(\\frac{f(y)}{p(y|\\theta)}\\right)f(y)dy\\]","tags":null,"title":"第5章","type":"docs"},{"authors":null,"categories":null,"content":"\rIntroduction to hierarchial models\rMany statistical applications involve multiple parameters (say, \\(\\theta_1,\\dots,\\theta_J\\)) that can be regarded as related or connected in some way by the structure of the problem.\n\rfor the group \\(j\\in 1{:}J\\), we have the observed data \\(y_{ij}\\), \\(i=1,\\dots,n_j\\) from the population distribution with unknown parameter \\(\\theta_j\\)\n\rwe use a prior distribution in which the \\(\\theta_j\\)’s are viewed as a sample from a common population distribution, say \\(p(\\theta|\\phi)\\), where \\(\\phi\\) is known as hyperparameters. Assume that \\(\\theta_j\\) are iid, i.e.,\r\\[p(\\theta|\\phi)=\\prod_{j=1}^Jp(\\theta_j|\\phi)\\]\n\r\r\rHierarchical model for Rats experiment\rThe experiment is used to estimate the probability \\(\\theta\\) of tumor in a population of female laboratory rats of type ‘F344’ that receive a zero dose of the drug. The data show that 4 out of 14 rats developed a kind of tumor.\n\rassume a binomial model for the number of tumors\rselect a prior from the conjugate family, i.e., \\(\\theta\\sim Beta(\\alpha,\\beta)\\)\rthe posterior is therefore \\(Beta(\\alpha+1,\\beta+10)\\)\r\rThe question is how to determine the hyperparameters \\(\\phi=(\\alpha,\\beta)\\)\n\rhistorical data are available on previous experiments on similar groups of rats: in the jth historical experiments, let the number of rats with tumors be \\(y_j\\) and the total number of rats be \\(n_j\\), the parameters for the populations are \\(\\theta_j\\), \\(j=1,\\dots,70\\).\rfor current experiment, let \\(y_{71},n_{71},\\theta_{71}\\) be the associated notations.\r\r\rHistorical data for the 70 historical experiments\r## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2\r## [24] 2 2 2 2 2 2 2 2 1 5 2 5 3 2 7 7 3 3 2 9 10 4 4\r## [47] 4 4 4 4 4 10 4 4 4 5 11 12 5 5 6 5 6 6 6 6 16 15 15\r## [70] 9 4\r## [1] 20 20 20 20 20 20 20 19 19 19 19 18 18 17 20 20 20 20 19 19 18 18 25\r## [24] 24 23 20 20 20 20 20 20 10 49 19 46 27 17 49 47 20 20 13 48 50 20 20\r## [47] 20 20 20 20 20 48 19 19 19 22 46 49 20 20 23 19 22 20 20 20 52 46 47\r## [70] 24 14\r\rViewed as separate models using uniform priors\r\rViewed as a pooled model using uniform prior\r\rUsing the historical data to estimate the hyperparameters\r\rthe sample mean and standard deviation of the 70 values \\(y_i/n_i\\) are 0.136 and 0.103\n\rlet \\(E[\\theta]=\\frac{\\alpha}{\\alpha+\\beta}=0.136\\) and \\(Var[\\theta]=\\frac{E[\\theta](1-E[\\theta])}{\\alpha+\\beta+1}=0.103\\)\n\r\\(\\hat{\\alpha}=1.4,\\ \\hat{\\beta}=8.6\\)\n\rfor the current exeriment, the posterior for \\(\\theta\\) is \\(Beta(5.4,18.6)\\), posterior mean is \\(0.223\\), standard deviation is 0.083.\n\r\rThere are several logical and practical problems with the approach of directly estimating a prior distribution from existing data:\n\rthe data will be used twice for inference about the first 70 experiments – overestimate our precision\n\rthe point estimate for \\(\\alpha,\\beta\\) seems arbitrary that necessarily ignores some posterior uncertainty\n\rthis is not the logic of Bayesian inference\n\r\r\rThe full Bayesian treatment of the hierarchical model\rSuppose the hyperparameters \\(\\phi\\) has its own prior distribution \\(p(\\phi)\\), which is called hyperprior distribution. The appropriate Bayesian posterior distribution is of the vector \\((\\phi,\\theta)\\).\n\rthe joint prior distribution is\r\\[p(\\phi,\\theta)=p(\\phi)p(\\theta|\\phi)\\]\n\rthe joint posterior distribution is\r\\[p(\\phi,\\theta|y)\\propto p(\\phi,\\theta)p(y|\\phi,\\theta)=p(\\phi)p(\\theta|\\phi)p(y|\\theta)\\]\n\r\rPreviously, we assumed \\(\\phi\\) was known, which is unrealistic; now we include the uncertainty in \\(\\phi\\) in the model.\n\rFully Bayesian analysis of conjugate hierarchical models\rConsider the setting in which \\(p(\\theta|\\phi)\\) is conjugate to the likelihood \\(p(y|\\theta)\\). For this case, it is easy to determine analytically \\[p(\\theta|\\phi,y)\\propto p(\\theta|\\phi)p(y|\\theta)\\]\n\rthe joint posterior density:\r\\[p(\\phi,\\theta|y)\\propto p(\\phi)p(\\theta|\\phi)p(y|\\theta)\\]\rthe marginal posterior density \\(p(\\phi|y)\\) can be computed via\r\\[p(\\phi|y)=\\int p(\\phi,\\theta|y)d \\theta\\]\r\r\\[\\text{or }p(\\phi|y)=\\frac{p(\\phi,\\theta|y)}{p(\\theta|\\phi,y)}\\]\n\rApplication to the model for rat tumors\rThe binomial model:\r\\[y_j\\sim Bin(n_j,\\theta_j),\\ j=1,\\dots,J=71\\]\nThe parameters \\(\\theta_j\\) are assumed to be independent samples from a beta distribution:\r\\[\\theta_j\\sim Beta(\\alpha,\\beta)\\]\nThe joint posterior density is\r\\[p(\\theta,\\alpha,\\beta|y)\\propto p(\\alpha,\\beta)p(\\theta|\\alpha,\\beta)p(y|\\theta)\\]\r\\[\\propto p(\\alpha,\\beta)\\prod_{j=1}^J\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta_j^{\\alpha-1}(1-\\theta_j)^{\\beta-1}\\prod_{j=1}^J\\theta_j^{y_j}(1-\\theta_j)^{n_j-y_j}\\]\n\\[p(\\theta|\\alpha,\\beta,y)=\\prod_{j=1}^J\\frac{\\Gamma(\\alpha+\\beta+n_j)}{\\Gamma(\\alpha+y_j)\\Gamma(\\beta+n_j-y_j)}\\theta_j^{\\alpha+y_i-1}(1-\\theta_j)^{\\beta+n_j-y_j-1}\\]\n\rApplication to the model for rat tumors\rThe marginal posterior density:\r\\[p(\\alpha,\\beta|y)\\propto p(\\alpha,\\beta)\\prod_{j=1}^J\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\frac{\\Gamma(\\alpha+y_j)\\Gamma(\\beta+n_j-y_j)}{\\Gamma(\\alpha+\\beta+n_j)}\\]\nChoosing a noninformative hyperprior distribution:\r\\[p(\\alpha,\\beta)\\propto (\\alpha+\\beta)^{-5/2}\\]\nThis implies that \\((\\alpha/(\\alpha+\\beta),(\\alpha+\\beta)^{-1/2})\\) is uniformly distributed.\n\rthe prior mean is \\(\\alpha/(\\alpha+\\beta)\\)\rthe prior variance is approximately \\((\\alpha+\\beta)^{-1}\\)\r\r\rPlot of the marginal posterior density\r\rCompare the separate model and hierarchical model\r\rHierarchical model based on normal distribution\rConsider \\(J\\) independent experiments, with experiment \\(j\\) estimating \\(\\theta_j\\) form \\(n_j\\) independent distributed data points \\(y_{ij}\\), each with known error variance \\(\\sigma^2\\), that is\r\\[y_{ij}|\\theta_j\\stackrel{iid}{\\sim} N(\\theta_j,\\sigma^2), \\text{ for }i=1,\\dots,n_j;\\ j=1,\\dots,J\\]\n\rdenote the sample mean of each group \\(j\\) as\r\\[\\bar{y}_{\\cdot j}=\\frac 1{n_j}\\sum_{i=1}^{n_j}y_{ij}\\]\n\rlet \\(\\sigma^2_j=\\sigma^2/n_j\\)\n\rthe likelihood for each \\(\\theta_j\\):\r\\[\\bar{y}_{\\cdot j}|\\theta_j\\sim N(\\theta_j,\\sigma_j^2)\\]\n\r\r\rHierarchical model based on normal distribution\r\rfor the convenience of conjugacy, assume the paramerters \\(\\theta_j\\) are drawn from a normal distribution with hyperparameters \\(\\mu,\\tau\\):\r\\[p(\\theta_1,\\dots,\\theta_J|\\mu,\\tau)=\\prod_{j=1}^J N(\\theta_j|\\mu,\\tau^2)\\]\n\rassign noninformative uniform hyperprior density to \\(\\mu\\) given \\(\\tau\\):\r\\[p(\\mu,\\tau)=p(\\mu|\\tau)p(\\tau)\\propto p(\\tau)\\]\n\rprior distribution for \\(\\tau\\): \\(p(\\tau)\\propto 1\\)\n\rthe joint posterior density is\r\\[p(\\theta,\\mu,\\tau|y)\\propto p(\\mu,\\tau)p(\\theta|\\mu,\\tau)p(y|\\theta)\\]\n\r\r\\[p(\\theta,\\mu,\\tau|y)\\propto p(\\mu,\\tau)\\prod_{j=1}^J N(\\theta_j|\\mu,\\tau^2)\\prod_{j=1}^JN(\\bar{y}_{\\cdot j}|\\theta_j,\\sigma_j^2)\\]\n\rHierarchical model based on normal distribution\r\rthe conditional posterior distirbution:\r\\[\\theta_j|\\mu,\\tau,y\\sim N(\\hat{\\theta}_j,V_j)\\]\r\rwhere\r\\[\\hat{\\theta}_j=\\frac{\\frac 1{\\sigma^2}\\bar{y}_{\\cdot j}+\\frac 1{\\tau^2}\\mu}{\\frac 1{\\sigma^2}+\\frac 1{\\tau^2}},\\ V_j=\\frac{1}{\\frac 1{\\sigma^2}+\\frac 1{\\tau^2}}\\]\n\rthe marginal posterior density can be computed in a simple way\r\\[p(\\mu,\\tau|y)\\propto p(\\mu,\\tau)p(y|\\mu,\\tau)\\]\n\r\\(\\bar{y}_{\\cdot j}|\\mu,\\tau\\sim N(\\mu,\\sigma_j^2+\\tau^2)\\)\n\r\r\\[p(\\mu,\\tau|y)\\propto p(\\mu,\\tau)\\prod_{j=1}^JN(\\bar{y}_{\\cdot j}|\\mu,\\sigma_j^2+\\tau^2)\\]\n\rHierarchical model based on normal distribution\r\rposterior distribution of \\(\\mu\\) given \\(\\tau\\)\r\\[\\mu|\\tau,y\\sim N(\\hat{\\mu},V_{\\mu})\\]\r\rwhere\r\\[\\hat{\\mu}=\\frac{\\sum_{j=1}^J \\frac 1{\\sigma_j^2+\\tau^2}\\bar{y}_{\\cdot j}}{\\sum_{j=1}^J \\frac 1{\\sigma_j^2+\\tau^2}},\\ V_{\\mu}^{-1}=\\sum_{j=1}^J \\frac 1{\\sigma_j^2+\\tau^2}\\]\n\rposterior distribution of \\(\\tau\\):\r\\[p(\\tau|y)=\\frac{p(\\mu,\\tau|y)}{p(\\mu|\\tau,y)}\\propto \\frac{p(\\tau)\\prod_{j=1}^JN(\\bar{y}_{\\cdot j}|\\mu,\\sigma_j^2+\\tau^2)}{N(\\mu|\\hat{\\mu},V_{\\mu})}\\]\r\r\\[p(\\tau|y)\\propto p(\\tau)V_{\\mu}^{1/2}\\prod_{j=1}^J(\\sigma_j^2+\\tau^2)^{-1/2}\\exp\\left(-\\frac{(\\bar{y}_{\\cdot j}-\\hat{\\mu})^2}{2(\\sigma_j^2+\\tau^2)}\\right)\\]\n\rExample: parallel experiments in eight schools\rA study was performanced for the Educational Testing Service to analyze the effects of special coaching programs on test scores. Seperate randomized experiments were performed to estimate the effects of coaching programs for the SAT-V (Verbal).\n\r\r\r\rSchool\rEstiamted treatment effect \\(y_j\\)\rStandard error of effect estimate \\(\\sigma_j\\)\r\r\r\rA\r28\r15\r\rB\r8\r10\r\rC\r-3\r16\r\rD\r7\r11\r\rE\r-1\r9\r\rF\r1\r11\r\rG\r18\r10\r\rH\r12\r18\r\r\r\r\rComparisons\r\rPlot the posterior summaries\r\r","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"bb84d9721a76c89184e5afa53efc4280","permalink":"/zh/courses/bayes/chap6/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/bayes/chap6/","section":"courses","summary":"Introduction to hierarchial models\rMany statistical applications involve multiple parameters (say, \\(\\theta_1,\\dots,\\theta_J\\)) that can be regarded as related or connected in some way by the structure of the problem.","tags":null,"title":"第6章","type":"docs"},{"authors":null,"categories":null,"content":"","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"6b2071c62f03321e7e8cae2727c1073d","permalink":"/zh/courses/stat/chap2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/zh/courses/stat/chap2/","section":"courses","summary":"","tags":null,"title":"第二章","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/zh/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/zh/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["何志坚","Xiaoqun Wang"],"categories":null,"content":"","date":1595203200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1595203200,"objectID":"2c6f811bd985d01771e98a6eb925817f","permalink":"/zh/publication/2020mcom/","publishdate":"2020-07-20T00:00:00Z","relpermalink":"/zh/publication/2020mcom/","section":"publication","summary":"Quantiles and expected shortfalls are usually used to measure risks of stochastic systems, which are often estimated by Monte Carlo methods. This paper focuses on the use of the quasi-Monte Carlo (QMC) method, whose convergence rate is asymptotically better than Monte Carlo in the numerical integration. We first prove the convergence of QMC-based quantile estimates under very mild conditions, and then establish a deterministic error bound of $ O(N^{-1/d})$ for the quantile estimates, where $ d$ is the dimension of the QMC point sets used in the simulation and $ N$ is the sample size. Under certain conditions, we show that the mean squared error (MSE) of the randomized QMC estimate for expected shortfall is $ o(N^{-1})$. Moreover, under stronger conditions the MSE can be improved to $ O(N^{-1-1/(2d-1)+\\epsilon })$ for arbitrarily small $ \\epsilon 0$.","tags":["QMC"],"title":"Convergence analysis of quasi-Monte Carlo sampling for quantile and expected shortfall","type":"publication"},{"authors":["何志坚","Xiaoqun Wang"],"categories":null,"content":"","date":1584662400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1584662400,"objectID":"3f45d91e380ae8564effac47c54d6a46","permalink":"/zh/publication/2020ec/","publishdate":"2020-03-20T00:00:00Z","relpermalink":"/zh/publication/2020ec/","section":"publication","summary":"Quasi-Monte Carlo (QMC) method is a useful numerical tool for pricing and hedging of complex financial derivatives. These problems are usually of high dimensionality and discontinuities. The two factors may significantly deteriorate the performance of the QMC method. This paper develops an integrated method that overcomes the challenges of the high dimensionality and discontinuities concurrently. For this purpose, a smoothing method is proposed to remove the discontinuities for some typical functions arising from financial engineering. To make the smoothing method applicable for more general functions, a new path generation method is designed for simulating the paths of the underlying assets such that the resulting function has the required form. The new path generation method has an additional power to reduce the effective dimension of the target function. Our proposed method caters for a large variety of model specifications, including the Black–Scholes, exponential normal inverse Gaussian Lévy, and Heston models. Numerical experiments dealing with these models show that in the QMC setting the proposed smoothing method in combination with the new path generation method can lead to a dramatic variance reduction for pricing exotic options with discontinuous payoffs and for calculating options’ Greeks. The investigation on the effective dimension and the related characteristics explains the significant enhancement of the combined procedure.","tags":["QMC"],"title":"An Integrated Quasi-Monte Carlo Method for Handling High Dimensional Problems with Discontinuities in Financial Engineering","type":"publication"},{"authors":["何志坚"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1567296000,"objectID":"c3cb8184491fd93b1926b7fc2f624ec1","permalink":"/zh/publication/2019sinum/","publishdate":"2019-04-25T00:00:00Z","relpermalink":"/zh/publication/2019sinum/","section":"publication","summary":"This paper studies the rate of convergence for conditional quasi--Monte Carlo (QMC), which is a counterpart of conditional Monte Carlo. We focus on discontinuous integrands defined on the whole of $\\mathbb{R}^d$, which can be unbounded. Under suitable conditions, we show that conditional QMC not only has the smoothing effect (up to infinitely times differentiable) but also can bring orders of magnitude reduction in integration error compared to plain QMC. Particularly, for some typical problems in options pricing and Greeks estimation, conditional randomized QMC that uses $n$ samples yields a mean error of $O(n^{-1+\\epsilon})$ for arbitrarily small $\\epsilon0$. As a byproduct, we find that this rate also applies to randomized QMC integration with all terms of the analysis of variance decomposition of the discontinuous integrand, except the one of highest order.","tags":["QMC"],"title":"On the Error Rate of Conditional Quasi-Monte Carlo for Discontinuous Functions","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026quot;Click to view the spoiler\u0026quot; \u0026gt;}} You found me! {{\u0026lt; /spoiler \u0026gt;}}  renders as\n Click to view the spoiler  You found me!    Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"/zh/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/zh/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Fei Xie","何志坚","Xiaoqun Wang"],"categories":null,"content":"","date":1555372800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1555372800,"objectID":"1411e3c16b556cfacc61385102d6518a","permalink":"/zh/publication/2019ejor/","publishdate":"2019-04-16T00:00:00Z","relpermalink":"/zh/publication/2019ejor/","section":"publication","summary":"Handling discontinuities in financial engineering is a challenging task when using quasi-Monte Carlo (QMC) method. This paper develops a so-called sequential importance sampling (SIS) method to remove multiple discontinuity structures sequentially for pricing discrete barrier options. The SIS method is a smoothing approach based on importance sampling, which yields an unbiased estimate with reduced variance. However, removing discontinuities still may not recover the superiority of QMC when the dimensionality of the problem is high. In order to handle the impact of high dimensionality on QMC, one promising strategy is to reduce the effective dimension of the problem. To this end, we develop a good path generation method with the smoothed estimator under the Black–Scholes model and models based on subordinated Brownian motion (e.g., Variance Gamma process). We find that the order of path generation influences the variance of the SIS estimator, and show how to choose optimally the first generation step. As confirmed by numerical experiments, the SIS method combined with a carefully chosen path generation method can significantly reduce the variance with improved rate of convergence. In addition, we show that the effective dimension is greatly reduced by the combined method, explaining the superiority of the proposed procedure from another perspective. The SIS method is also applicable for general models (with the Euler discretization). The smoothing effect of the SIS method facilitates the use of general dimension reduction techniques in reclaiming the efficiency of QMC.","tags":["QMC","Finance"],"title":"An importance sampling-based smoothing approach for quasi-Monte Carlo simulation of discrete barrier options","type":"publication"},{"authors":["何志坚","Lingjiong Zhu"],"categories":null,"content":"","date":1553040000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1553040000,"objectID":"8826caf8fdc1dc62d05b3fd52094d933","permalink":"/zh/publication/2019cs/","publishdate":"2019-03-20T00:00:00Z","relpermalink":"/zh/publication/2019cs/","section":"publication","summary":"Recently, He and Owen (J R Stat Soc Ser B 78(4):917–931, 2016) proposed the use of Hilbert’s space filling curve (HSFC) in numerical integration as a way of reducing the dimension from d1 to d=1. This paper studies the asymptotic normality of the HSFC-based estimate when using one-dimensional stratification inputs. In particular, we are interested in using scrambled van der Corput sequence in any base b≥2 with sample sizes of the form n=bm, for which the sampling scheme is extensible in the sense of multiplying the sample size by a factor of b. We show that the estimate has an asymptotic normal distribution for functions in C1([0,1]d), excluding the trivial case of constant functions. The asymptotic normality also holds for discontinuous functions under mild conditions. Previously, it was only known that scrambled (0, m, d)-net quadratures enjoy the asymptotic normality for smooth enough functions, whose mixed partial gradients satisfy a Hölder condition. As a by-product, we find lower bounds for the variance of the HSFC-based estimate. Particularly, for non-trivial functions in C1([0,1]d), the lower bound is of order n−1−2/d, which matches the rate of the upper bound established in He and Owen (2016).","tags":["QMC"],"title":"Asymptotic normality of extensible grid sampling","type":"publication"},{"authors":["何志坚"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"/zh/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/zh/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":["Zhijian He"],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation | Zhijian He\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/zh/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/zh/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["何志坚"],"categories":null,"content":"","date":1518998400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1518998400,"objectID":"8898cf540742f4dd21b46d6ff67227f3","permalink":"/zh/publication/2018mcom/","publishdate":"2018-02-19T00:00:00Z","relpermalink":"/zh/publication/2018mcom/","section":"publication","summary":"This paper studies randomized quasi-Monte Carlo (QMC) sampling for discontinuous integrands having singularities along the boundary of the unit cube $ [0,1]^d$. Both discontinuities and singularities are extremely common in the pricing and hedging of financial derivatives and have a tremendous impact on the accuracy of QMC. It was previously known that the root mean square error of randomized QMC is only $ o(n^{1/2})$ for discontinuous functions with singularities. We find that under some mild conditions, randomized QMC yields an expected error of $ O(n^{-1/2-1/(4d-2)+\\epsilon })$ for arbitrarily small $ \\epsilon 0$. Moreover, one can get a better rate if the boundary of discontinuities is parallel to some coordinate axes. As a by-product, we find that the expected error rate attains $ O(n^{-1+\\epsilon })$ if the discontinuities are QMC-friendly, in the sense that all the discontinuity boundaries are parallel to coordinate axes. The results can be used to assess the QMC accuracy for some typical problems from financial engineering.","tags":["QMC"],"title":"Quasi-Monte Carlo for Discontinuous Integrands with Singularities along the Boundary of the Unit Cube","type":"publication"},{"authors":["Chengfeng Weng","Xiaoqun Wang","何志坚"],"categories":null,"content":"","date":1490054400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1490054400,"objectID":"8516606bccfff907f1e9ecd5dcf31ff8","permalink":"/zh/publication/2017sisc/","publishdate":"2017-03-21T00:00:00Z","relpermalink":"/zh/publication/2017sisc/","section":"publication","summary":"Discontinuities and high dimensionality are common in the problems of pricing and hedging of derivative securities. Both factors have a tremendous impact on the accuracy of the quasi--Monte Carlo (QMC) method. An ideal approach to improve the QMC method is to transform the functions to make them smoother and having smaller effective dimension. This paper develops a two-step procedure to tackle the challenging problems of both the discontinuity and the high dimensionality concurrently. In the first step, we adopt the smoothing method to remove the discontinuities of the payoff function, improving the smoothness. In the second step, we propose a general dimension reduction method (called the CQR method) to reduce the effective dimension such that the better quality of QMC points in their initial dimensions can be fully exploited. The CQR method is based on the combination of the $k$-means clustering algorithm and the QR decomposition. The $k$-means clustering algorithm, a classical algorithm of machine learning, is used to find some representative linear structures inherent in the function, which are used to construct a matching function of the smoothed function. The matching function serves as an approximation of the smoothed function but has a simpler form, and it is used to find the required transformation. Extensive numerical experiments on option pricing and Greeks estimation demonstrate that the combination of the smoothing method and dimension reduction in QMC achieves substantially larger variance reduction even in high dimension than dealing with either discontinuities or high dimensionality single sidedly.","tags":["QMC","Finance"],"title":"Efficient Computation of Option Prices and Greeks by Quasi-Monte Carlo Method with Smoothing and Dimension reduction","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/zh/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/zh/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/zh/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/zh/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Chengfeng Weng","Xiaoqun Wang","何志坚"],"categories":null,"content":"","date":1458950400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1458950400,"objectID":"40c0e92f08cc5b0dcf5f387ddabe9701","permalink":"/zh/publication/2016ejor/","publishdate":"2016-03-26T00:00:00Z","relpermalink":"/zh/publication/2016ejor/","section":"publication","summary":"Discontinuities are common in the pricing of financial derivatives and have a tremendous impact on the accuracy of quasi-Monte Carlo (QMC) method. While if the discontinuities are parallel to the axes, good efficiency of the QMC method can still be expected. By realigning the discontinuities to be axes-parallel, [Wang \\\u0026 Tan, 2013] succeeded in recovering the high efficiency of the QMC method for a special class of functions. Motivated by this work, we propose an auto-realignment method to deal with more general discontinuous functions. The k-means clustering algorithm, a classical algorithm of machine learning, is used to select the most representative normal vectors of the discontinuity surface. By applying this new method, the discontinuities of the resulting function are realigned to be friendly for the QMC method. Numerical experiments demonstrate that the proposed method significantly improves the performance of the QMC method.","tags":["QMC","Finance"],"title":"An Auto-Realignment Method in Quasi-Monte Carlo for Pricing Financial Derivatives with Jump Structures","type":"publication"},{"authors":["何志坚","Art Owen"],"categories":null,"content":"","date":1458259200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1458259200,"objectID":"b5099d86c503769215544a71b997eec6","permalink":"/zh/publication/2016jrssb/","publishdate":"2016-03-18T00:00:00Z","relpermalink":"/zh/publication/2016jrssb/","section":"publication","summary":"We study the properties of points in $[0,1]^d$ generated by applying Hilbert's space-filling curve to uniformly distributed points in $[0,1]$. For deterministic sampling we obtain a discrepancy of $O(n^{-1/d})$ for $d\\ge2$. For random stratified sampling, and scrambled van der Corput points, we get a mean squared error of $O(n^{-1-2/d})$ for integration of  Lipschitz continuous integrands, when $d\\ge3$. These rates are the same as one gets by sampling on $d$ dimensional grids and they show a deterioration with increasing $d$.  The rate for Lipschitz functions is however best possible at that level of smoothness and is better than plain IID sampling. Unlike grids, space-filling curve sampling provides points at any desired sample size, and the van der Corput version is extensible in $n$. We also introduce a class of piecewise Lipschitz functions whose discontinuities are in rectifiable sets described via Minkowski content. Although these functions may have infinite variation in the sense of Hardy and Krause, they  can be integrated with a mean squared error of $O(n^{-1-1/d})$. It was previously known only that the rate was $o(n^{-1})$. Other space-filling curves, such as those due to Sierpinski and Peano, also attain these rates, while upper bounds for the Lebesgue curve are somewhat worse, as if the dimension were $\\log_2(3)$ times as high.","tags":["QMC"],"title":"Extensible Grids -- Uniform Sampling on a Space-Filling Curve","type":"publication"},{"authors":["何志坚","Xiaoqun Wang"],"categories":null,"content":"","date":1446076800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1446076800,"objectID":"3f4e7b31652e546b341fcbe7ace28d41","permalink":"/zh/publication/2015sinum/","publishdate":"2015-10-29T00:00:00Z","relpermalink":"/zh/publication/2015sinum/","section":"publication","summary":"This paper studies the convergence rate of randomized quasi--Monte Carlo (RQMC) for discontinuous functions, which are often of infinite variation in the sense of Hardy and Krause. It was previously known that the root mean square error (RMSE) of RQMC is only $o(n^{-1/2})$ for discontinuous functions. For certain discontinuous functions in $d$ dimensions, we prove that the RMSE of RQMC is $O(n^{-1/2-1/(4d-2)+\\epsilon})$ for any $\\epsilon0$ and arbitrary $n$. If some discontinuity boundaries are parallel to some coordinate axes, the rate can be improved to $O(n^{-1/2-1/(4d_u-2)+\\epsilon})$, where $d_u$ denotes the so-called irregular dimension, that is, the number of axes which are not parallel to the discontinuity boundaries. Moreover, this paper shows that the RMSE is $O(n^{-1/2-1/(2d)})$ for certain indicator functions.","tags":["QMC"],"title":"On the Convergence Rate of Randomized Quasi-Monte Carlo for Discontinuous Functions","type":"publication"},{"authors":null,"categories":["R"],"content":"\rR Markdown\rThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars)\r## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00\rfit \u0026lt;- lm(dist ~ speed, data = cars)\rfit\r## ## Call:\r## lm(formula = dist ~ speed, data = cars)\r## ## Coefficients:\r## (Intercept) speed ## -17.579 3.932\r\rIncluding Plots\rYou can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1))\rpie(\rc(280, 60, 20),\rc(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;),\rcol = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;),\rinit.angle = -50, border = NA\r)\r\rFigure 1: A fancy pie chart.\r\r\r","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1437703994,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"/zh/post/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/zh/post/2015-07-23-r-rmarkdown/","section":"post","summary":"R Markdown\rThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":["何志坚","Xiaoqun Wang"],"categories":null,"content":"","date":1395100800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1395100800,"objectID":"d7deb53560592c606a36a761fa0ef360","permalink":"/zh/publication/2014sisc/","publishdate":"2014-03-18T00:00:00Z","relpermalink":"/zh/publication/2014sisc/","section":"publication","summary":"Quasi-Monte Carlo (QMC) method is a powerful numerical tool for pricing complex derivative securities, whose accuracy is affected by the smoothness of the integrands. The payoff functions of many financial derivatives involve two types of non-smooth factors --- an indicator function (called jump structure) and a positive part of a smooth function (called kink structure). This paper develops a good path generation method (PGM) for recovering the superiority of QMC method on problems involving multiple such structures. This is achieved by realigning these structures such that the associated non-smooth surfaces are parallel to as many coordinate axes as possible. The proposed method has the advantage of addressing different structures according to their importance. We also offer a systematic measurement of different structures for quantifying and then ranking their importance. Numerical experiments demonstrate that the proposed method is more efficient than traditional PGMs for pricing exotic options, such as straddle Asian options, digital options and barrier options. The numerical results confirm that both the jumps and kinks have tremendous impacts on the performance of QMC method.","tags":["QMC","Finance"],"title":"Good Path Generation Methods in Quasi-Monte Carlo for Pricing Financial Derivatives","type":"publication"}]