---
title: "Applications of MLE"
author: "Zhijian He"
date: '`r format(Sys.Date())`'
CJKmainfont: SimSun
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = F,message = F)
```


## 案例一：车流量数据

The following data show the number of occupants in passenger cars observed during one hour at a busy intersection in Los Angeles. Suppose it can be assumed that these data follow a geometric distribution, $p_X(k;p) = (1-p)^{k-1}p,k=1,2,...$. Estimate $p$ and compare the observed and expected frequencies for each value of $X$.

| Number of Occupants | Frequency |
| -- | -- |
| 1 | 678 |
| 2 | 227 |
| 3 | 56  |
| 4 | 28  |
| 5 | 8   |
|6+ | 14  |
| Total | 1011 |


**Solution**: Let $N_i$ be the observed frequencies for $i$ occupants，$i=1,\dots,5$, $N_6$ be the observed frequencies for $6+$ occupants. We thus have $$(N_1,\dots,N_6)\sim \text{multinomial}(n;p_1,p_2,\dots,p_6),$$
where $p_i=(1-p)^{i-1}p,\ i=1,\dots,5$, $p_6=1-\sum_{i=1}^5 p_i=(1-p)^5$, and $n=1011$.

The likelihood function is 
$$L(p)= P(N_1=n_1,\dots,N_6=n_6)=\frac{n!}{n_1!\dots n_6!}p_1^{n_1}\dots p_6^{n_6}.$$
 
The log-likelihood is 
$$\ln L(p)= \sum_{i=1}^6 n_i\log p_i+\text{const}=\left(\sum_{i=1}^5 n_i\right)\ln p +\left[\sum_{i=2}^6(i-1)n_i\right]\ln (1-p)+\text{const}.$$

As a result,
$$\frac{\partial\ln L(p)}{\partial p}=\left(\sum_{i=1}^5 n_i\right)/ p -\left[\sum_{i=2}^6(i-1)n_i\right]/(1-p)=0.$$

The MLE is 
$$\hat p_{MLE} = \frac{N_1+N_2+\dots+N_5}{N_1+2N_2+3N_3+4N_4+5N_5+5N_6}.$$

```{r, fig.align='center'}
library('ggplot2')
n = c(678,227,56,28,8,14)
loglik <- function(p){
  return(sum(head(n,-1))*log(p)+sum((1:(length(n)-1))*n[-1])*log(1-p))
}
curve(loglik,0,1,bty = "l")
mle = sum(n)/(sum(1:6*n)-tail(n,1))
points(mle,loglik(mle),col='red',pch=8)
abline(v=mle,lty=2)
text(mle*1.2,loglik(mle)*2,paste0("  the mle for p is ",round(mle,3)))

n2 = sum(n)*c(mle,(1-mle)*mle,(1-mle)^2*mle,(1-mle)^3*mle,(1-mle)^4*mle,(1-mle)^5)
df = data.frame(
  no = c(1:6-0.2,1:6+0.2),
  freq = c(n,n2),
  type = c(rep('observed',6),rep('expected',6))
)
ggplot(df,aes(x=no,y=freq,fill=type)) +
  geom_bar(stat="identity",width=0.4) +
  xlab('Number of Occupants')+
  ylab('Frequency')+
  theme(title=element_text(size=15),legend.text=element_text(size=15))
```



Using the data, we get 
$$\hat p_{MLE} = \frac{n_1+n_2+\dots+n_5}{n_1+2n_2+3n_3+4n_4+5n_5+5n_6}=`r mle`.$$ 
The estimated average number of occupants is 
$$\frac{1}{\hat p_{MLE}} =`r 1/mle`.$$


## 案例二：删失数据(censored data)

Suppose $Y_i\stackrel{iid}\sim f(y;\theta)$, but if $Y_i> t_i$ then we don't see $Y_i$ we only learn that $Y_i> t_i$. Let $\delta_i=1$ if $Y_i$ was observed and $\delta_i=0$ otherwise. The likelihood function is given by
$$L(\theta)=\prod_{i=1}^n f(y_i;\theta)^{\delta_i}(1-F(t_i;\theta))^{1-\delta_i},$$
where $F(t;\theta)$ is the PDF of $Y_i$. 

**Exponential model**: Assume that $Y_i\stackrel{iid}\sim Exp(\lambda)$. Then we have
$$L(\lambda)=\prod_{i=1}^n (\lambda \exp(-\lambda y_i))^{\delta_i}(\exp(-\lambda t_i))^{1-\delta_i}=\lambda^{n_1}\exp[-\sum_{i=1}^n(\delta_i y_i+(1-\delta_i)t_i)\lambda],$$
where $n_1 = \sum_{i=1}^n \delta_i.$ The log-likelihood is 
$$\ln L(\lambda) = n_1\ln \lambda -\sum_{i=1}^n(\delta_i y_i+(1-\delta_i)t_i)\lambda.$$

$$\frac{\partial\ln L(\lambda)}{\partial \lambda}=\frac {n_1}\lambda-\sum_{i=1}^n(\delta_i y_i+(1-\delta_i)t_i)=0.$$

The MLE is given by
$$\hat\lambda_{MLE}=\frac {n_1}{\sum_{i=1}^n(\delta_i Y_i+(1-\delta_i)t_i)}=\frac{n_1}{\sum_{i=1}^n\min(Y_i,t_i)}=\frac{n_1}{\sum_{i=1}^nX_i},$$
where $X_i=\min(Y_i,t_i)$ is the observed data.
The estimated average survival time is $1/\hat\lambda_{MLE}$. The probability of survival time no less than $t_0$ is $\exp(-\hat\lambda_{MLE} t_0)$.


### Acute Myelogenous Leukemia survival data (急性骨髓性白血病生存数据)

```{r}
library(survival) 
knitr::kable(head(aml,10),caption = "Acute Myelogenous Leukemia survival data",align = 'c')
with(aml, Surv(time, status))
lambda1 = sum(aml$status)/sum(aml$time)
```
The MLE of $\lambda$ is $\hat\lambda_{MLE}=`r lambda1`$. The estimated average survival time is $1/\hat\lambda_{MLE}=`r 1/lambda1`$. The probability $P(Y>10)$ is estimated by $\exp(-10\times\hat\lambda_{MLE})=`r exp(-10*lambda1)`$. 

###  Lung Cancer Data (肺癌数据)
```{r}
library(survival) 
knitr::kable(head(lung,10),caption = "Lung Cancer Data",align = 'c')
lambda2 = sum(lung$status==2)/sum(lung$time)
```


The MLE of $\lambda$ is $\hat\lambda_{MLE}=`r lambda2`$.  The estimated average survival time is $1/\hat\lambda_{MLE}=`r 1/lambda2`$.

### What's the MLE for Weibull distribution

The Weibull distribution with shape parameter $\gamma>0$ and rate parameter $\lambda>0$ has density given by
$$f(x;\gamma,\lambda) = \lambda\gamma x^{\gamma-1} \exp(- \lambda x^\gamma)$$
for $x > 0$. The cumulative distribution function is $F(x) = 1 - \exp(-  \lambda x^\gamma)$ on $x > 0$. Particularly, if $\gamma=1$, Weibull distribution turns out to be Exponential distribution.

```{r,fig.align='center'}
plot(seq(0,5,by=0.01),dweibull(seq(0,5,by=0.01), shape = 2),type='l',xlab='x',ylab='density',main='Weibull distribution',bty = "l")
```


Suppose $Y_i\stackrel{iid}\sim f(y;\gamma,\lambda)$. How to estimate $\gamma$ and $\lambda$ for the two datasets above? How to estimate the average survival time $\lambda^{-1/\gamma}\Gamma(1+1/\gamma)$? 
The likelihood  equation cannot be solved algebraically so you may need a numerical procedure.
The Newton-Raphson algorithm is one way to solve such equations numerically.


## 案例三：高斯混合模型(Gaussian mixture model, GMM)

The Gaussian mixture distribution has density given by 
$$f(x)=\sum_{j=1}^J w_j \phi(x;\mu_j,\sigma^2_j),$$
where $w_j>0$ and $\sum_{j=1}^J w_j=1$, $\phi(x;\mu,\sigma^2)$ is the PDF of $N(\mu,\sigma^2)$, and $J$ is a given positive integer.

How to estimate the parameters $w_j,\mu_j,\sigma_j^2$? The most popular method is the Expectation-Maximization (EM) algorithm proposed by Dempster et al. (1977).

> Dempster, A.P., Laird, N.M. and Rubin, D.B. (1977), Maximum Likelihood from Incomplete Data Via the EM Algorithm. Journal of the Royal Statistical Society: Series B (Methodological), 39: 1-22.  https://doi.org/10.1111/j.2517-6161.1977.tb01600.x

This paper is cited 62040 times as of 2020/10/7.

### Galaxies data

The galaxies data in the MASS package (Venables and Ripley, 2002) is a frequently used example for
Gaussian mixture models. It contains the velocities of 82 galaxies from a redshift survey ([红移巡天](https://baike.baidu.com/item/%E7%BA%A2%E7%A7%BB/189542)：红移在物理学和天文学领域，指物体的电磁辐射由于某种原因频率降低的现象，在可见光波段，表现为光谱的谱线朝红端移动了一段距离，即波长变长、频率降低。红移的现象目前多用于天体的移动及规律的预测上。BY 百度百科) in the Corona
Borealis region (北冕座地区). Clustering of galaxy velocities reveals information about the large scale structure of the
universe.

```{r,fig.align='center'}
library(MASS)
gal <- galaxies/1000
plot(x = c(5, 40), y = c(0, 0.3), type = "n", bty = "l",
     xlab = "velocity of galaxy (1000km/s)", ylab = "density",main = 'Kernel density estimation')
rug(gal)
lines(density(gal, width = 3.25, n = 200), lty = 1)
```


The Mclust function from the mclust package (Fraley et al, 2012) is used to fit Gaussian mixture models.
The code below fits a model with G=4 components to the galaxies data, allowing the variances to be unequal
(model="V").

```{r,fig.align='center'}
library(mclust,quietly=TRUE)
J = 4 # number of components
fit = Mclust(gal, G=J, model="V")
summary(fit)
mle = rbind(fit$parameters$pro,fit$parameters$mean,fit$parameters$variance$sigmasq)
row.names(mle) = c('weight','mean','variance')
knitr::kable(mle,caption = 'MLEs',align = 'c')
xx = seq(5,40,length.out = 1000)
yy = rep(0,1000)
for(i in 1:J){
  yy = yy + fit$parameters$pro[i]*dnorm(xx,fit$parameters$mean[i],sqrt(fit$parameters$variance$sigmasq[i]))
}
plot(xx,yy, ylab="density", xlab="velocity of galaxy (1000km/s)",main='GMM fitted',
     xlim = c(5, 40), ylim = c(0, 0.3), bty = "l",type = 'l')
rug(gal)
```


